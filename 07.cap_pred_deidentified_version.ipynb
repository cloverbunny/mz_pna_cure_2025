{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running python 3.9.6\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tableone import TableOne\n",
    "from functools import reduce, partial\n",
    "\n",
    "import statistics\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Evaluation of models\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GroupKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve, auc, confusion_matrix, average_precision_score, classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "import pyroc\n",
    "import optuna\n",
    "import random\n",
    "import statannotations.Annotator\n",
    "\n",
    "import shap\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "mpl.rcParams['pdf.fonttype'] = 42  # edit-able in illustrator\n",
    "mpl.rcParams['font.sans-serif'] = 'Arial'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "        \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_feature_names(columns):\n",
    "    # handle specific names\n",
    "    special_tokens = ['gcs', 'fio2', 'po2', 'rass', 'pco2', 'wbc', 'rdw', 'ldh', 'sofa', 'bmi']\n",
    "    \n",
    "    pretty_names = []\n",
    "\n",
    "    for col in columns:\n",
    "        if col == 'sofa_points_htn':\n",
    "            pretty_names.append('Cardiovascular SOFA Score')\n",
    "        elif col.startswith('po2_fio2_ratio_'):\n",
    "            suffix = col.split('_')[-1].capitalize()\n",
    "            pretty_names.append(r'PaO$_2$/FiO$_2$ ' + suffix)\n",
    "        elif col.startswith('po2_art_'):\n",
    "            suffix = col.split('_')[-1].capitalize()\n",
    "            pretty_names.append(r'PaO$_2$ ' + suffix)\n",
    "        elif col.startswith('abs_lymphocytes_'):\n",
    "            suffix = col.split('_')[-1].capitalize()\n",
    "            pretty_names.append('Absolute Lymphocytes ' + suffix)\n",
    "        elif col == 'edw_adm_age':\n",
    "            pretty_names.append('Age')\n",
    "        elif col.startswith('pco2_art_'):\n",
    "            suffix = col.split('_')[-1].capitalize()\n",
    "            pretty_names.append(r'PaCO$_2$ ' + suffix)\n",
    "        elif col.startswith('fio2_'):\n",
    "            suffix = col.split('_')[-1].capitalize()\n",
    "            pretty_names.append(r'FiO$_2$ ' + suffix)\n",
    "        else:\n",
    "            parts = col.split('_')\n",
    "            pretty_parts = []\n",
    "            for part in parts:\n",
    "                if part.lower() in special_tokens:\n",
    "                    pretty_parts.append(part.upper())\n",
    "                else:\n",
    "                    pretty_parts.append(part.capitalize())\n",
    "            pretty_names.append(' '.join(pretty_parts))\n",
    "    return pretty_names\n",
    "\n",
    "# SHAP plot\n",
    "# Initialize SHAP explainer\n",
    "def plot_shap(model,data, plot_title, plot=True, save_path=None, max_display=10):\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(data)\n",
    "\n",
    "    # get cleaner column names\n",
    "    pretty_names = prettify_feature_names(data.columns)\n",
    "\n",
    "    # Plot SHAP values\n",
    "    if plot:\n",
    "        new_title =  plot_title.replace('_', ' ')\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(shap_values, data, feature_names=pretty_names, max_display=max_display, show=False)\n",
    "        plt.title(new_title, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "    return shap_values\n",
    "\n",
    "# ROC plot\n",
    "def plot_auroc(y_train, y_test, y_train_pred_proba, y_test_pred_proba, title,\n",
    "               fontsize=14, figsize=(10, 10)):\n",
    "\n",
    "    y_train_preds = y_train_pred_proba\n",
    "    y_test_preds = y_test_pred_proba\n",
    "\n",
    "    y_train = y_train.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "\n",
    "    # ROC curve data\n",
    "    fpr1, tpr1, _ = roc_curve(y_train, y_train_preds)\n",
    "    fpr2, tpr2, _ = roc_curve(y_test, y_test_preds)\n",
    "\n",
    "    auc1 = roc_auc_score(y_train, y_train_preds)\n",
    "    auc2 = roc_auc_score(y_test, y_test_preds)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=figsize)\n",
    "    ax.plot(fpr1, tpr1, color='C1', label=\"Train set (AUROC = \"+str(round(auc1, 3))+\")\")\n",
    "    ax.plot(fpr2, tpr2, color='C2', label=\"Test set (AUROC = \"+str(round(auc2, 3))+\")\")\n",
    "\n",
    "    # Add line for random chance\n",
    "    ax.plot([0, 1], [0, 1], color='black', linestyle='--', label='Random Chance')\n",
    "\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=fontsize)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=fontsize)\n",
    "    ax.tick_params(axis='x', labelsize=fontsize - 2)\n",
    "    ax.tick_params(axis='y', labelsize=fontsize - 2)\n",
    "    ax.grid(linestyle=':')\n",
    "    ax.legend(loc='best', fontsize=fontsize - 2)\n",
    "    ax.set_title(title, fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_shap_customized_axis(model,data, plot_title, \n",
    "                              left_label=None, right_label=None,\n",
    "                              plot=True, save_path=None, \n",
    "                              max_display=10):\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(data)\n",
    "\n",
    "    # get cleaner column names\n",
    "    pretty_names = prettify_feature_names(data.columns)\n",
    "\n",
    "    # Plot SHAP values\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values, data, feature_names=pretty_names,\n",
    "            max_display=max_display, show=False\n",
    "        )\n",
    "\n",
    "        # Axis and colorbar tweaks\n",
    "        ax = plt.gca()\n",
    "        fig = plt.gcf()\n",
    "        ax.tick_params(axis='y', labelsize=18)\n",
    "        ax.tick_params(axis='x', labelsize=12)\n",
    "        \n",
    "        # Colorbar tweak\n",
    "        if fig.axes and (left_label is not None or right_label is not None):\n",
    "            colorbar_ax = fig.axes[-1]\n",
    "            colorbar_ax.tick_params(labelsize=15)\n",
    "            colorbar_ax.set_yticklabels(['Low/No', 'High/Yes'])\n",
    "            colorbar_ax.yaxis.label.set_size(10)\n",
    "\n",
    "            # Custom left/right labels under the colorbar\n",
    "            if left_label is not None:\n",
    "                ax.text(-0.1, -0.18, left_label,\n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=15,\n",
    "                    horizontalalignment='left',\n",
    "                    fontweight='bold')\n",
    "\n",
    "            if right_label is not None:\n",
    "                ax.text(1.1, -0.18, right_label,\n",
    "                    transform=ax.transAxes,\n",
    "                    fontsize=15,\n",
    "                    horizontalalignment='right',\n",
    "                    fontweight='bold')\n",
    "\n",
    "        plt.title(plot_title.replace('_', ' '), fontsize=20, pad=20)\n",
    "        # plt.xlabel('SHAP value (impact on model output)', fontsize=14)\n",
    "        ax.xaxis.label.set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        # plt.subplots_adjust(bottom=0.22) \n",
    "\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "\n",
    "def cross_validation_metrics(best_model, X, y, episode_ids, n_splits=5):\n",
    "    # Set up n-fold cross-validation\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    # Arrays to store metrics\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    precisions = []\n",
    "    aps = []\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "\n",
    "    for train_index, val_index in gkf.split(X, y, groups=episode_ids):\n",
    "        X_tr, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_tr, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Fit model\n",
    "        best_model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_val_preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, thresholds = roc_curve(y_val.astype(int), y_val_preds)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        aucs.append(auc_score)\n",
    "        \n",
    "        # Interpolate TPR\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        \n",
    "\n",
    "        # PRC\n",
    "        precision, recall, _ = precision_recall_curve(y_val.astype(int), y_val_preds)\n",
    "        ap_score = average_precision_score(y_val.astype(int), y_val_preds)\n",
    "        aps.append(ap_score)\n",
    "        # Interpolate precision to mean_recall grid\n",
    "        interp_precision = np.interp(mean_recall, recall[::-1], precision[::-1])  # flip for increasing recall\n",
    "        precisions.append(interp_precision)\n",
    "\n",
    "\n",
    "    # Compute mean TPR and AUC\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0 \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "\n",
    "    # Compute means/std for PRC\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    std_precision = np.std(precisions, axis=0)\n",
    "    mean_ap = np.mean(aps)\n",
    "    std_ap = np.std(aps)\n",
    "\n",
    "    return {\n",
    "        \"aurocs\": aucs,\n",
    "        \"mean_fpr\": mean_fpr,\n",
    "        \"mean_tpr\": mean_tpr,\n",
    "        \"std_tpr\": std_tpr,\n",
    "        \"aps\": aps,\n",
    "        \"mean_recall\": mean_recall,\n",
    "        \"mean_precision\": mean_precision,\n",
    "        \"std_precision\": std_precision\n",
    "    }\n",
    "\n",
    "# get metric results\n",
    "def get_metrics_dict(results):\n",
    "    metrics = results['metrics']\n",
    "    \n",
    "    accuracy = metrics.get('accuracy', None)\n",
    "    precision = metrics.get('ppv', None) or metrics.get('precision', None)\n",
    "    recall = metrics.get('sensitivity', None) or metrics.get('recall', None)\n",
    "    specificity = metrics.get('specificity', None)\n",
    "    f1 = metrics.get('f1', None) or metrics.get('f1-score', None)\n",
    "    auroc = metrics.get('auroc', None)\n",
    "    aupr = metrics.get('aupr', None)\n",
    "    npv = metrics.get('npv', None)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Specificity\": specificity,\n",
    "        \"F1-score\": f1,\n",
    "        \"AUROC\": auroc,\n",
    "        \"AUPR\": aupr,\n",
    "        \"NPV\": npv,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Path and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file (Please replace the path to your file)\n",
    "input_path = \"./data/input.csv\"\n",
    "\n",
    "# Patient to exclude (A file include patient id to exclude, default column name is id, please chnage to the name meet your file)\n",
    "exclude_path = \"./data/exclude_list.csv\"\n",
    "\n",
    "# Define id column\n",
    "id_col = 'pt_study_id'\n",
    "\n",
    "# Output path\n",
    "output_path = './output/plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Ids: 702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/flfk9jd16tv0pc1fnh97zcmc0000gp/T/ipykernel_1139/3356229952.py:1: DtypeWarning: Columns (179,188,189,190,215,218) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(input_path)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(input_path)\n",
    "exclude_ids = pd.read_csv(exclude_path)['id'].tolist()\n",
    "\n",
    "# Exlcude patient not meet the criteria\n",
    "data = data.loc[~data[id_col].isin(exclude_ids), :]\n",
    "print(\"Number of Unique Ids:\", data[id_col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Episode cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean episode resolution\n",
    "def get_episode_resolution_l2(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "    elif 'indeterminate' in x.lower():\n",
    "        return 'indeterminate'        \n",
    "    elif 'cure' in x.lower():\n",
    "        return 'cured'\n",
    "    elif 'super' in x.lower() or 'persistence' in x.lower(): \n",
    "        return 'not cured'  \n",
    "\n",
    "data['episode_resolution_d7_l2'] = data['clin_impression_d78'].apply(get_episode_resolution_l2)\n",
    "data['episode_resolution_d10_l2'] = data['clin_impression_d10'].apply(get_episode_resolution_l2)\n",
    "data['episode_resolution_d14_l2'] = data['clin_impression_d14'].apply(get_episode_resolution_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Exclude viral cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data.episode_etiology.eq('Viral')\n",
    "viral_episodes_id = data.loc[idx, 'episode_id'].unique()\n",
    "data = data[~data['episode_id'].isin(viral_episodes_id)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get patient without day 7 episode resolution\n",
    "idx = (\n",
    "    data.episode_etiology.notna() \n",
    "    & data.episode_etiology.ne('Viral') \n",
    "    & data.episode_resolution_d7_l2.isna()\n",
    ")\n",
    "episodes_without_d7 = data.episode_id[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Create episode_day column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['episode_day'] = data.groupby(['pt_study_id','episode_id']).cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Update episode resolution d7 with cured column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for those patients have < 7 day episode, update their d7 using cured column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in episodes_without_d7:\n",
    "    idx = data.episode_id.eq(ep)\n",
    "    if idx.sum() < 7:\n",
    "        data.loc[idx, 'episode_resolution_d7_l2'] = data.cured[idx].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for cases with all missing values in clinical adjudication columns, updated as global clinical cure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients with all missing clinical adjudication: 27\n"
     ]
    }
   ],
   "source": [
    "idx = (\n",
    "    (data['cured'].notna()) &\n",
    "    (data[['episode_resolution_d7_l2', 'episode_resolution_d10_l2', 'episode_resolution_d14_l2']].isna().all(axis=1)) &\n",
    "    (data['episode_duration']>=7) & (data['episode_duration'].notna())\n",
    ")\n",
    "    \n",
    "missing_d7_id = data.loc[idx,'episode_id'].unique()\n",
    "data.loc[idx, 'episode_resolution_d7_l2'] = data.loc[idx, 'cured'].str.lower()\n",
    "\n",
    "print(\"Patients with all missing clinical adjudication:\", len(missing_d7_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 keep patients have at least 3 consecutive episode days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/flfk9jd16tv0pc1fnh97zcmc0000gp/T/ipykernel_1139/3207953244.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data.groupby(['pt_study_id', 'episode_id'])\n"
     ]
    }
   ],
   "source": [
    "def is_consecutive_episode_day(group, day):\n",
    "    consecutive_day_list = list(range(1, day+1))\n",
    "    if len(group) < day:\n",
    "        return False\n",
    "    return sorted(group['episode_day'].head(day).tolist()) == consecutive_day_list\n",
    "\n",
    "\n",
    "n_day = 3\n",
    "data = data.sort_values(by=['pt_study_id', 'admission_datetime', 'episode_id', 'episode_day'])\n",
    "mask = (\n",
    "    data.groupby(['pt_study_id', 'episode_id'])\n",
    "        .apply(lambda group: is_consecutive_episode_day(group, day=n_day))\n",
    "        .reset_index(name='has_consecutive_day')\n",
    ")\n",
    "idx = mask[mask['has_consecutive_day'] == True][['pt_study_id', 'episode_id']]\n",
    "data = data.merge(idx, on=['pt_study_id', 'episode_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffill episode resolution column\n",
    "mask = data['episode_id'].notna()\n",
    "data.loc[mask, 'episode_resolution_d7_l2'] = (\n",
    "    data.loc[mask]\n",
    "    .groupby('episode_id')['episode_resolution_d7_l2']\n",
    "    .transform(lambda x: x.fillna(x.dropna().iloc[0]) if x.notna().any() else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Convert categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['episode_id'].notna()\n",
    "data.loc[mask, 'episode_category'] = (\n",
    "    data.loc[mask]\n",
    "    .groupby('episode_id')['episode_category']\n",
    "    .transform(lambda x: x.fillna(x.dropna().iloc[0]) if x.notna().any() else x)\n",
    ")\n",
    "\n",
    "data['episode_category'] = data['episode_category'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Binarize outcome variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['d7_episode_resolution_binary'] = np.where(data.episode_resolution_d7_l2=='cured',0 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get CAP only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest CAP episode duration day: 30.0\n"
     ]
    }
   ],
   "source": [
    "#keeping CAP episodes only\n",
    "ep_cap = data.episode_id[data.episode_category == 'CAP']\n",
    "cap = data.loc[data.episode_id.isin(ep_cap)].copy()\n",
    "\n",
    "#longest duration of CAP episode\n",
    "print(\"Longest CAP episode duration day:\", cap.episode_duration.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Get day1 to day3  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list = list(range(1, 4))\n",
    "cap_1to3 = cap[cap.episode_day.isin(day_list)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_cols = [\n",
    "                'pt_study_id',\n",
    "                'episode_day',\n",
    "                'episode_id',\n",
    "                'd7_episode_resolution_binary'\n",
    "]\n",
    "\n",
    "demo_feature = [\n",
    "    'edw_adm_age',\n",
    "    'bmi'\n",
    "]\n",
    "\n",
    "\n",
    "lab_feature = [\n",
    "            # 'wbc_avg',\n",
    "            'wbc_max',\n",
    "            # 'abs_lymphocytes_avg',\n",
    "            'abs_lymphocytes_max',\n",
    "            # 'abs_neutrophils_avg',\n",
    "            'abs_neutrophils_max',\n",
    "            # 'abs_eosinophils_avg',\n",
    "            'abs_eosinophils_max',\n",
    "            # 'hemoglobin_avg',\n",
    "            'hemoglobin_min',\n",
    "            # 'platelet_avg',\n",
    "            'platelet_min',\n",
    "            # 'rdw_avg',\n",
    "            'rdw_max',\n",
    "            # 'sodium_avg',\n",
    "            'sodium_min',\n",
    "            # 'bicarbonate_avg',\n",
    "            'bicarbonate_min',\n",
    "            # 'creatinine_avg',\n",
    "            'creatinine_max',\n",
    "            # 'bun_avg',\n",
    "            'bun_max',\n",
    "            # 'glucose_avg',\n",
    "            'glucose_min',\n",
    "            # 'albumin_avg',\n",
    "            'albumin_min',\n",
    "            # 'bilirubin_avg',\n",
    "            'bilirubin_max',\n",
    "            # 'pt_avg',\n",
    "            'pt_max',\n",
    "            # 'ptt_avg',\n",
    "            'ptt_max',\n",
    "            # 'crp_avg',\n",
    "            'crp_max',\n",
    "            # 'lactic_acid_avg',\n",
    "            'lactic_acid_max',\n",
    "            # 'ldh_avg',\n",
    "            'ldh_max',\n",
    "            'sofa_points_p_f_ratio',\n",
    "            'sofa_points_platelet',\n",
    "            'sofa_points_bilirubin',\n",
    "            'sofa_points_htn',\n",
    "            'sofa_points_gcs',\n",
    "            'sofa_points_renal',\n",
    "            'sofa_score'\n",
    "]\n",
    "\n",
    "ventilator_feature = [\n",
    "    'peep_max',\n",
    "    'plateau_pressure_max',\n",
    "    'peak_airway_pressure_max',\n",
    "    'minute_ventilation_max',\n",
    "    'driving_pressure',\n",
    "    'ph_art_min',\n",
    "    'pco2_art_max'\n",
    "]\n",
    "\n",
    "med_feature = [\n",
    "                'hydrocort_equivalent_steroid_dose_day', \n",
    "                'cumulative_steroid_dose_until_today',\n",
    "                'cumulative_nat_score',\n",
    "                'received_remdesivir', \n",
    "                'remdesivir_study_drug'\n",
    "]\n",
    "\n",
    "halms_feature = [\n",
    "                    'temperature_avg', \n",
    "                    'temperature_max', \n",
    "                    'heart_rate_avg', \n",
    "                    'heart_rate_max', \n",
    "                    'systolic_blood_pressure_avg', \n",
    "                    'systolic_blood_pressure_min', \n",
    "                    'diastolic_blood_pressure_avg', \n",
    "                    'diastolic_blood_pressure_min', \n",
    "                    'respiratory_rate_avg', \n",
    "                    'respiratory_rate_max', \n",
    "                    'oxygen_saturation_avg', \n",
    "                    'oxygen_saturation_min', \n",
    "                    'norepinephrine_avg', \n",
    "                    'norepinephrine_max', \n",
    "                    'rass_avg', \n",
    "                    'rass_min', \n",
    "                    'gcs_eye_opening_avg', \n",
    "                    'gcs_motor_response_avg', \n",
    "                    'gcs_verbal_response_avg', \n",
    "                    'gcs_eye_opening_min', \n",
    "                    'gcs_motor_response_min', \n",
    "                    'gcs_verbal_response_min', \n",
    "                    'fio2_avg', \n",
    "                    'fio2_max', \n",
    "                    'po2_art_avg', \n",
    "                    'po2_art_min', \n",
    "                    'po2_fio2_ratio_avg', \n",
    "                    'po2_fio2_ratio_min', \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# all variables to keep\n",
    "feature_columns_all = static_cols + halms_feature + lab_feature + ventilator_feature + med_feature + demo_feature\n",
    "cap_1to3_sub = cap_1to3[feature_columns_all].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create binning columns for Halm's criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gcs_total first\n",
    "cap_1to3_sub['gcs_total_avg'] = cap_1to3_sub['gcs_eye_opening_avg'] + cap_1to3_sub['gcs_motor_response_avg'] + cap_1to3_sub['gcs_verbal_response_avg']\n",
    "cap_1to3_sub['gcs_total_min'] = cap_1to3_sub['gcs_eye_opening_min'] + cap_1to3_sub['gcs_motor_response_min'] + cap_1to3_sub['gcs_verbal_response_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HR > 100 as 1 (Halms)\n",
    "cap_1to3_sub['heart_rate_bin'] = np.where(cap_1to3_sub.heart_rate_avg > 100, 1, 0)\n",
    "\n",
    "# Set RR > 24 as 1 (Halms)\n",
    "cap_1to3_sub['respiratory_rate_bin'] = np.where(cap_1to3_sub.respiratory_rate_avg > 24, 1, 0)\n",
    "\n",
    "# Set SBP >= 90 as 1 (Halms)\n",
    "cap_1to3_sub['systolic_blood_pressure_bin'] = np.where(cap_1to3_sub.systolic_blood_pressure_avg >= 90, 1, 0)\n",
    "\n",
    "# Set stable temperature (<= 99F and > 95.9F) as 0 (modified Halms)\n",
    "cap_1to3_sub['temperature_bin'] = np.where((cap_1to3_sub.temperature_avg <= 95.9) | (cap_1to3_sub.temperature_avg > 99), 1, 0)\n",
    "\n",
    "# Set oxygen saturation < 90 as 1\n",
    "cap_1to3_sub['oxygen_saturation_bin'] = np.where(cap_1to3_sub.oxygen_saturation_avg < 90, 1, 0)\n",
    "\n",
    "# Set RASS >= -2 as 1\n",
    "cap_1to3_sub['rass_score_bin'] = np.where(cap_1to3_sub.rass_avg >= -2, 1, 0)\n",
    "\n",
    "# Set GCS >= 11 as 1 (this is a little random, but setting cutoff at 10 gives better GCS contribution than setting cutoff at 12)\n",
    "cap_1to3_sub['gcs_total_bin'] = np.where(cap_1to3_sub.gcs_total_avg >= 11, 1, 0)\n",
    "\n",
    "# Set pao2fio2_ratio >= 400 as 1\n",
    "cap_1to3_sub['po2_fio2_ratio_bin'] = np.where(cap_1to3_sub.po2_fio2_ratio_avg >= 400, 1, 0)\n",
    "\n",
    "# Set norepinephrine_flag if not 0\n",
    "cap_1to3_sub['norepinephrine_flag'] = np.where(cap_1to3_sub.norepinephrine_avg > 0, 1, 0)\n",
    "\n",
    "# Clinical stability is defined as halms_vs = 0, otherwise 1\n",
    "cap_1to3_sub['halms_complex'] = np.where((cap_1to3_sub.heart_rate_bin == 0) &\n",
    "                                        (cap_1to3_sub.respiratory_rate_bin == 0) &\n",
    "                                        (cap_1to3_sub.systolic_blood_pressure_bin == 0) &\n",
    "                                        (cap_1to3_sub.temperature_bin == 0) &\n",
    "                                        (cap_1to3_sub.oxygen_saturation_bin == 0) &\n",
    "                                        (cap_1to3_sub.rass_score_bin == 0) &\n",
    "                                        (cap_1to3_sub.gcs_total_bin == 0) &\n",
    "                                        (cap_1to3_sub.po2_fio2_ratio_bin == 0) &\n",
    "                                        (cap_1to3_sub.norepinephrine_flag == 0), 0, 1)\n",
    "\n",
    "\n",
    "# Clinical stability is defined as halms_vs = 0, otherwise 1\n",
    "cap_1to3_sub['halms_vs'] = np.where((cap_1to3_sub.heart_rate_bin == 0) &\n",
    "                                (cap_1to3_sub.respiratory_rate_bin == 0) &\n",
    "                                (cap_1to3_sub.systolic_blood_pressure_bin == 0) &\n",
    "                                (cap_1to3_sub.temperature_bin == 0) &\n",
    "                                (cap_1to3_sub.oxygen_saturation_bin == 0), 0, 1)\n",
    "\n",
    "# Clinical stability is defined as halms_pred = 0, otherwise 1\n",
    "cap_1to3_sub['halms_pred'] = cap_1to3_sub['halms_complex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Define Halm's related variables group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 1: Halms binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "halms_bin_col = [\n",
    "    'temperature_bin',\n",
    "    'heart_rate_bin',\n",
    "    'systolic_blood_pressure_bin',\n",
    "    'norepinephrine_flag',\n",
    "    'respiratory_rate_bin',\n",
    "    'oxygen_saturation_bin',\n",
    "    'po2_fio2_ratio_bin',\n",
    "    'rass_score_bin',\n",
    "    'gcs_total_bin'\n",
    "] + static_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 2: No binning, avg and worst Halm's variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "halms_feature_sub = [\n",
    "                   'temperature_avg', \n",
    "                   'temperature_max', \n",
    "                   'heart_rate_avg', \n",
    "                   'heart_rate_max', \n",
    "                   'systolic_blood_pressure_avg', \n",
    "                   'systolic_blood_pressure_min', \n",
    "                   'respiratory_rate_avg', \n",
    "                   'respiratory_rate_max', \n",
    "                   'oxygen_saturation_avg', \n",
    "                   'oxygen_saturation_min', \n",
    "                   'norepinephrine_avg', \n",
    "                   'norepinephrine_max', \n",
    "                   'rass_avg', \n",
    "                   'rass_min', \n",
    "                   'gcs_eye_opening_avg', \n",
    "                   'gcs_motor_response_avg', \n",
    "                   'gcs_verbal_response_avg',\n",
    "                   'gcs_eye_opening_min', \n",
    "                   'gcs_motor_response_min', \n",
    "                   'gcs_verbal_response_min', \n",
    "                   'fio2_avg', \n",
    "                   'fio2_max', \n",
    "                   'po2_art_avg', \n",
    "                   'po2_art_min', \n",
    "                   'po2_fio2_ratio_avg', \n",
    "                   'po2_fio2_ratio_min',\n",
    "] + static_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 3: No binning, avg Halm's variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "halms_feature_avg = [c for c in halms_feature_sub if c.endswith('_avg')] + static_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables 4: No binning, Worst Halm's variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "halms_feature_worst = [c for c in halms_feature_sub if not c.endswith('_avg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize result dictionary to store all model results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Create baseline (Halm's criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = cap_1to3_sub['d7_episode_resolution_binary']\n",
    "y_pred = cap_1to3_sub['halms_pred']\n",
    "\n",
    "# For rule-based methods, predicted \"probabilities\" are just the predicted class\n",
    "y_pred_prob = y_pred\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "sensitivity = recall_score(y_true, y_pred)\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "ppv = precision_score(y_true, y_pred)\n",
    "npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_true, y_pred),\n",
    "    'auroc': roc_auc_score(y_true, y_pred) if len(np.unique(y_true)) > 1 else None,\n",
    "    'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
    "    'report': classification_report(y_true, y_pred, output_dict=True),\n",
    "    'sensitivity': sensitivity,\n",
    "    'specificity': specificity,\n",
    "    'ppv': ppv,\n",
    "    'npv': npv,\n",
    "    'f1': f1,\n",
    "}\n",
    "\n",
    "baseline_results = {\n",
    "    'y_test': y_true,\n",
    "    'test_pred': y_pred,\n",
    "    'test_pred_prob': y_pred_prob,\n",
    "    'metrics': metrics,\n",
    "    'model': None,\n",
    "    'cv_results': None,\n",
    "}\n",
    "\n",
    "results['halms_baseline'] = baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define fine-tuning and model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_and_train_xgb(X_train, y_train, pt_ids, n_trials=50, random_state=42):\n",
    "    def objective(trial, X, y, pt_ids):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"random_state\": random_state,\n",
    "            \"verbosity\": 0,\n",
    "            \"enable_categorical\": True,\n",
    "            \"tree_method\": \"hist\"\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "        gkf = GroupKFold(n_splits=5)\n",
    "        train_scores = []\n",
    "        val_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in gkf.split(X, y, groups=pt_ids):\n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            y_val_fold = y.iloc[val_idx]\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_pred = model.predict_proba(X_train_fold)[:, 1]\n",
    "            val_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "        \n",
    "            train_auc = roc_auc_score(y_train_fold, train_pred)\n",
    "            val_auc = roc_auc_score(y_val_fold, val_pred)\n",
    "            \n",
    "            train_scores.append(train_auc)\n",
    "            val_scores.append(val_auc)\n",
    "    \n",
    "        avg_train = np.mean(train_scores)\n",
    "        avg_val = np.mean(val_scores)\n",
    "\n",
    "        overfitting_penalty = max(0, avg_train - avg_val - 0.1)\n",
    "        return avg_val - overfitting_penalty\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=random_state)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(partial(objective, X=X_train, y=y_train, pt_ids=pt_ids), n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params.update({\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": random_state,\n",
    "        \"verbosity\": 0,\n",
    "        \"enable_categorical\": True,\n",
    "        \"tree_method\": \"hist\"\n",
    "    })\n",
    "\n",
    "    model = XGBClassifier(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, threshold=0.5):\n",
    "    # Predict probabilities\n",
    "    y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Predict class using threshold\n",
    "    y_test_pred = (y_test_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    # Confusion matrix for specificity/NPV/etc.\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    sensitivity = recall_score(y_test, y_test_pred)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    auroc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    ppv = precision_score(y_test, y_test_pred)\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_test_pred_proba)\n",
    "    aupr = auc(recall, precision)\n",
    "\n",
    "    print(f\"Test Set Evaluation\")\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Sensitivity: {sensitivity:.3f}\")\n",
    "    print(f\"Specificity: {specificity:.3f}\")\n",
    "    print(f\"AUROC: {auroc:.3f}\")\n",
    "    print(f\"F1 Score: {f1:.3f}\")\n",
    "    print(f\"AUPR: {aupr:.3f}\")\n",
    "    print(f\"PPV: {ppv:.3f}\")\n",
    "    print(f\"NPV: {npv:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"train_pred\": y_train_pred_proba,\n",
    "        \"test_pred\": y_test_pred_proba,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"specificity\": specificity,\n",
    "            \"auroc\": auroc,\n",
    "            \"f1\": f1,\n",
    "            \"aupr\": aupr,\n",
    "            \"ppv\": ppv,\n",
    "            \"npv\": npv,\n",
    "            \"confusion_matrix\": confusion_matrix(y_test, y_test_pred)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb_model_pipeline(model_name, \n",
    "                       X_train, X_test, y_train, y_test, pt_ids_train, n_splits=10,\n",
    "                       n_trials=30, random_state=42, threshold=0.5, plot_sp=True, \n",
    "                       max_display=10, save_path=False):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Make a copy\n",
    "    results['X_train'] = X_train\n",
    "    results['X_test'] = X_test\n",
    "    results['y_train'] = y_train\n",
    "    results['y_test'] = y_test\n",
    "\n",
    "    # Step 2: Fine-tune and train\n",
    "    model, best_params = fine_tune_and_train_xgb(X_train, y_train, pt_ids_train,\n",
    "                                                 n_trials=n_trials, random_state=random_state)\n",
    "    results['model'] = model\n",
    "    results['best_parameters'] = best_params\n",
    "\n",
    "    # Step 3: Evaluation\n",
    "    eval_result = evaluate_model(model, X_train, X_test,\n",
    "                                 y_train, y_test, threshold=threshold)\n",
    "    results['metrics'] = eval_result['metrics']\n",
    "    results['train_pred'] = eval_result['train_pred']\n",
    "    results['test_pred'] = eval_result['test_pred']\n",
    "\n",
    "    # Step 4: Cross-validation\n",
    "    results['cv_results'] = cross_validation_metrics(model, X_train, y_train, pt_ids_train, n_splits=n_splits)\n",
    "\n",
    "    # Step 5: SHAP\n",
    "    results['shap_values'] = plot_shap(model, X_test, plot_title=model_name, plot=plot_sp, save_path=save_path, max_display=max_display)\n",
    "\n",
    "    return model_name, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'avg_and_worst_Halm\\'s_features': halms_feature_sub + demo_feature,\n",
    "    'avg_Halm\\'s_features': halms_feature_avg + demo_feature,\n",
    "    'worst_Halm\\'s_features': halms_feature_worst + demo_feature,\n",
    "    'Halm\\'s_and_labs_features': halms_feature_worst + lab_feature + demo_feature,\n",
    "    'Halm\\'s_and_ventilator_features': halms_feature_worst + ventilator_feature + demo_feature,\n",
    "    'Halm\\'s_and_meds_features': halms_feature_worst + med_feature + demo_feature,\n",
    "    'Halm\\'s_and_labs_meds_and_ventilator_features': halms_feature_worst + lab_feature + ventilator_feature + med_feature + demo_feature,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:19,861] A new study created in memory with name: no-name-e18261c1-671c-4227-8d0b-aa30fce9db53\n",
      "[I 2025-07-03 10:17:19,978] Trial 0 finished with value: 0.3389808515998992 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.3389808515998992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes:\n",
      "Train: 68, Test: 17\n",
      "Number of unique patients:\n",
      "Train: 68, Test: 17\n",
      "Running xgb_avg_and_worst_Halm's_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:20,063] Trial 1 finished with value: 0.3008679768203578 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 0 with value: 0.3389808515998992.\n",
      "[I 2025-07-03 10:17:20,129] Trial 2 finished with value: 0.3719438145628623 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 2 with value: 0.3719438145628623.\n",
      "[I 2025-07-03 10:17:20,222] Trial 3 finished with value: 0.3121201814058957 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 2 with value: 0.3719438145628623.\n",
      "[I 2025-07-03 10:17:20,374] Trial 4 finished with value: 0.3529793398841018 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 2 with value: 0.3719438145628623.\n",
      "[I 2025-07-03 10:17:20,529] Trial 5 finished with value: 0.3040287226001511 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 2 with value: 0.3719438145628623.\n",
      "[I 2025-07-03 10:17:20,722] Trial 6 finished with value: 0.34019400352733675 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 2 with value: 0.3719438145628623.\n",
      "[I 2025-07-03 10:17:20,953] Trial 7 finished with value: 0.3534895439657345 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 2 with value: 0.3719438145628623.\n",
      "[I 2025-07-03 10:17:21,083] Trial 8 finished with value: 0.3881265688717187 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.3881265688717187.\n",
      "[I 2025-07-03 10:17:21,232] Trial 9 finished with value: 0.32705719324766924 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.3881265688717187.\n",
      "[I 2025-07-03 10:17:21,427] Trial 10 finished with value: 0.4340767102451403 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 10 with value: 0.4340767102451403.\n",
      "[I 2025-07-03 10:17:21,613] Trial 11 finished with value: 0.4319388921549415 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 10 with value: 0.4340767102451403.\n",
      "[I 2025-07-03 10:17:21,761] Trial 12 finished with value: 0.34651045603426567 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.07568854089179115, 'subsample': 0.9959735872518112, 'colsample_bytree': 0.5082196100884397}. Best is trial 10 with value: 0.4340767102451403.\n",
      "[I 2025-07-03 10:17:21,958] Trial 13 finished with value: 0.4490551622802429 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.012268998021885573, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.5017435095529454}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:22,131] Trial 14 finished with value: 0.32256991685563097 and parameters: {'n_estimators': 165, 'max_depth': 8, 'learning_rate': 0.07871338854502816, 'subsample': 0.8947385331597324, 'colsample_bytree': 0.6738167152482915}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:22,335] Trial 15 finished with value: 0.33909045099521296 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.10941179359723172, 'subsample': 0.8968212694350243, 'colsample_bytree': 0.5513502207746599}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:22,522] Trial 16 finished with value: 0.3473759133282942 and parameters: {'n_estimators': 177, 'max_depth': 8, 'learning_rate': 0.051236385539058536, 'subsample': 0.8993222364137526, 'colsample_bytree': 0.5666310315969064}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:22,669] Trial 17 finished with value: 0.44575280978917786 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.013630265887535653, 'subsample': 0.9270627421637063, 'colsample_bytree': 0.5008284044744004}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:22,804] Trial 18 finished with value: 0.3506122448979593 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.05514095319534378, 'subsample': 0.8592704696008102, 'colsample_bytree': 0.6703690344652179}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:22,883] Trial 19 finished with value: 0.4161479800683412 and parameters: {'n_estimators': 58, 'max_depth': 9, 'learning_rate': 0.11780146270112259, 'subsample': 0.5054945946218856, 'colsample_bytree': 0.6158737822642005}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:23,028] Trial 20 finished with value: 0.3313252708490805 and parameters: {'n_estimators': 116, 'max_depth': 6, 'learning_rate': 0.051059430079181845, 'subsample': 0.9399779806955342, 'colsample_bytree': 0.5502192851588042}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:23,241] Trial 21 finished with value: 0.4475081731142062 and parameters: {'n_estimators': 162, 'max_depth': 7, 'learning_rate': 0.011358681404389923, 'subsample': 0.9202685958641561, 'colsample_bytree': 0.5045775502136167}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:23,485] Trial 22 finished with value: 0.41903943058704984 and parameters: {'n_estimators': 183, 'max_depth': 7, 'learning_rate': 0.013821972170467822, 'subsample': 0.9283698879056905, 'colsample_bytree': 0.5492229999946834}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:23,663] Trial 23 finished with value: 0.36963214915595877 and parameters: {'n_estimators': 161, 'max_depth': 9, 'learning_rate': 0.0421523206963664, 'subsample': 0.8412115958099132, 'colsample_bytree': 0.5505100236806726}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:23,804] Trial 24 finished with value: 0.3815079365079367 and parameters: {'n_estimators': 114, 'max_depth': 7, 'learning_rate': 0.06629601698648506, 'subsample': 0.8979338809467867, 'colsample_bytree': 0.613922234877748}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:23,954] Trial 25 finished with value: 0.37404132023179637 and parameters: {'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.0384693912482143, 'subsample': 0.9392553337574732, 'colsample_bytree': 0.5266592863360915}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:24,191] Trial 26 finished with value: 0.40888976761257756 and parameters: {'n_estimators': 193, 'max_depth': 9, 'learning_rate': 0.012148381364633828, 'subsample': 0.8677449222274675, 'colsample_bytree': 0.5854829990858776}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:24,382] Trial 27 finished with value: 0.3722474174855127 and parameters: {'n_estimators': 158, 'max_depth': 6, 'learning_rate': 0.03353852541658516, 'subsample': 0.9994365274677256, 'colsample_bytree': 0.5101840576904929}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:24,484] Trial 28 finished with value: 0.348843537414966 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.06929754749528991, 'subsample': 0.9400510567433623, 'colsample_bytree': 0.5461458548624096}. Best is trial 13 with value: 0.4490551622802429.\n",
      "[I 2025-07-03 10:17:24,634] Trial 29 finished with value: 0.27180146132527094 and parameters: {'n_estimators': 231, 'max_depth': 8, 'learning_rate': 0.2945807951599052, 'subsample': 0.8177747665945824, 'colsample_bytree': 0.500178682808982}. Best is trial 13 with value: 0.4490551622802429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.725\n",
      "Sensitivity: 0.708\n",
      "Specificity: 0.741\n",
      "AUROC: 0.812\n",
      "F1 Score: 0.708\n",
      "AUPR: 0.851\n",
      "PPV: 0.708\n",
      "NPV: 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:25,108] A new study created in memory with name: no-name-09204874-ed3d-4b4f-b353-a198c7fd3e42\n",
      "[I 2025-07-03 10:17:25,199] Trial 0 finished with value: 0.4116641471403376 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.4116641471403376.\n",
      "[I 2025-07-03 10:17:25,261] Trial 1 finished with value: 0.4028697404887883 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 0 with value: 0.4116641471403376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xgb_avg_Halm's_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:25,315] Trial 2 finished with value: 0.4530272108843537 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 2 with value: 0.4530272108843537.\n",
      "[I 2025-07-03 10:17:25,388] Trial 3 finished with value: 0.41399974804736706 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 2 with value: 0.4530272108843537.\n",
      "[I 2025-07-03 10:17:25,508] Trial 4 finished with value: 0.41589443184681285 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 2 with value: 0.4530272108843537.\n",
      "[I 2025-07-03 10:17:25,632] Trial 5 finished with value: 0.388219954648526 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 2 with value: 0.4530272108843537.\n",
      "[I 2025-07-03 10:17:25,776] Trial 6 finished with value: 0.40429453262786597 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 2 with value: 0.4530272108843537.\n",
      "[I 2025-07-03 10:17:25,950] Trial 7 finished with value: 0.44254220206601136 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 2 with value: 0.4530272108843537.\n",
      "[I 2025-07-03 10:17:26,042] Trial 8 finished with value: 0.45423681701804086 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.45423681701804086.\n",
      "[I 2025-07-03 10:17:26,156] Trial 9 finished with value: 0.4249609473418997 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.45423681701804086.\n",
      "[I 2025-07-03 10:17:26,304] Trial 10 finished with value: 0.45960065507684533 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 10 with value: 0.45960065507684533.\n",
      "[I 2025-07-03 10:17:26,447] Trial 11 finished with value: 0.4618291761148904 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:26,566] Trial 12 finished with value: 0.4606512975560594 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.07568854089179115, 'subsample': 0.9959735872518112, 'colsample_bytree': 0.5082196100884397}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:26,691] Trial 13 finished with value: 0.44274376417233585 and parameters: {'n_estimators': 149, 'max_depth': 8, 'learning_rate': 0.07317753931253784, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.5032838495114452}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:26,810] Trial 14 finished with value: 0.40808390022675745 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.08271198621292061, 'subsample': 0.8947385331597324, 'colsample_bytree': 0.6738167152482915}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:26,978] Trial 15 finished with value: 0.4441017888636939 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.10941179359723172, 'subsample': 0.9954031050651094, 'colsample_bytree': 0.5606698426825126}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:27,129] Trial 16 finished with value: 0.45338624338624356 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.05310285317997031, 'subsample': 0.8972085438693564, 'colsample_bytree': 0.5494290740202485}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:27,251] Trial 17 finished with value: 0.4343990929705216 and parameters: {'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.12380730590737224, 'subsample': 0.9975360994382818, 'colsample_bytree': 0.5015619499860838}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:27,374] Trial 18 finished with value: 0.43196523053665914 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.0554574607526747, 'subsample': 0.8620716116675406, 'colsample_bytree': 0.6332588755180084}. Best is trial 11 with value: 0.4618291761148904.\n",
      "[I 2025-07-03 10:17:27,485] Trial 19 finished with value: 0.504731470798845 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.010518021411655965, 'subsample': 0.9251949705755246, 'colsample_bytree': 0.5609787030310569}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:27,602] Trial 20 finished with value: 0.4491332774354423 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.01153587643501299, 'subsample': 0.9371278043555231, 'colsample_bytree': 0.67784917070681}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:27,680] Trial 21 finished with value: 0.5036067019400353 and parameters: {'n_estimators': 56, 'max_depth': 6, 'learning_rate': 0.05487003845317831, 'subsample': 0.9487608843470481, 'colsample_bytree': 0.5554024649480812}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:27,753] Trial 22 finished with value: 0.49413101225858425 and parameters: {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.04335610854526337, 'subsample': 0.9321265198239379, 'colsample_bytree': 0.5592392251202983}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:27,824] Trial 23 finished with value: 0.4643837116240771 and parameters: {'n_estimators': 51, 'max_depth': 5, 'learning_rate': 0.04932417361396768, 'subsample': 0.9288960538855838, 'colsample_bytree': 0.5960222027864037}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:27,908] Trial 24 finished with value: 0.44935801867657366 and parameters: {'n_estimators': 71, 'max_depth': 5, 'learning_rate': 0.040641474118889145, 'subsample': 0.8708295648585197, 'colsample_bytree': 0.5752592792572376}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:27,991] Trial 25 finished with value: 0.48749811035525326 and parameters: {'n_estimators': 66, 'max_depth': 6, 'learning_rate': 0.061145590382180676, 'subsample': 0.9380044194203563, 'colsample_bytree': 0.5450870264737138}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:28,102] Trial 26 finished with value: 0.4439021164021165 and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.03298332631240775, 'subsample': 0.8366733523272175, 'colsample_bytree': 0.6096463057799174}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:28,187] Trial 27 finished with value: 0.471360544217687 and parameters: {'n_estimators': 75, 'max_depth': 7, 'learning_rate': 0.06414068091251138, 'subsample': 0.898486982193985, 'colsample_bytree': 0.552777355439934}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:28,263] Trial 28 finished with value: 0.44823808901704243 and parameters: {'n_estimators': 53, 'max_depth': 6, 'learning_rate': 0.040521309871798514, 'subsample': 0.9451849285352418, 'colsample_bytree': 0.662095348361586}. Best is trial 19 with value: 0.504731470798845.\n",
      "[I 2025-07-03 10:17:28,374] Trial 29 finished with value: 0.4424855127236079 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.09060843620543044, 'subsample': 0.8743254500872933, 'colsample_bytree': 0.6207056512173403}. Best is trial 19 with value: 0.504731470798845.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.706\n",
      "Sensitivity: 0.625\n",
      "Specificity: 0.778\n",
      "AUROC: 0.765\n",
      "F1 Score: 0.667\n",
      "AUPR: 0.792\n",
      "PPV: 0.714\n",
      "NPV: 0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:28,635] A new study created in memory with name: no-name-3e92b621-e2c2-4966-bf73-448a8f2fc50a\n",
      "[I 2025-07-03 10:17:28,723] Trial 0 finished with value: 0.35385361552028216 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:28,781] Trial 1 finished with value: 0.31631267321743517 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 0 with value: 0.35385361552028216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xgb_worst_Halm's_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:28,837] Trial 2 finished with value: 0.35321113630637446 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:28,908] Trial 3 finished with value: 0.3366439909297053 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:29,017] Trial 4 finished with value: 0.32597883597883615 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:29,137] Trial 5 finished with value: 0.2987528344671201 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:29,255] Trial 6 finished with value: 0.3274870028472373 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:29,402] Trial 7 finished with value: 0.32457797933988386 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 0 with value: 0.35385361552028216.\n",
      "[I 2025-07-03 10:17:29,479] Trial 8 finished with value: 0.3753128134840209 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.3753128134840209.\n",
      "[I 2025-07-03 10:17:29,584] Trial 9 finished with value: 0.3131040564373898 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.3753128134840209.\n",
      "[I 2025-07-03 10:17:29,707] Trial 10 finished with value: 0.4113309397833206 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:29,826] Trial 11 finished with value: 0.4096365583270346 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:29,931] Trial 12 finished with value: 0.3952557319223987 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.07568854089179115, 'subsample': 0.9959735872518112, 'colsample_bytree': 0.5082196100884397}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:30,055] Trial 13 finished with value: 0.4096704399413761 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.012268998021885573, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.5017435095529454}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:30,172] Trial 14 finished with value: 0.34661627614008583 and parameters: {'n_estimators': 165, 'max_depth': 8, 'learning_rate': 0.07871338854502816, 'subsample': 0.8947385331597324, 'colsample_bytree': 0.6738167152482915}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:30,322] Trial 15 finished with value: 0.3233938019652304 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.10941179359723172, 'subsample': 0.8968212694350243, 'colsample_bytree': 0.5513502207746599}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:30,449] Trial 16 finished with value: 0.3604673721340389 and parameters: {'n_estimators': 177, 'max_depth': 8, 'learning_rate': 0.051236385539058536, 'subsample': 0.8993222364137526, 'colsample_bytree': 0.5666310315969064}. Best is trial 10 with value: 0.4113309397833206.\n",
      "[I 2025-07-03 10:17:30,556] Trial 17 finished with value: 0.4412058272567304 and parameters: {'n_estimators': 109, 'max_depth': 7, 'learning_rate': 0.013630265887535653, 'subsample': 0.9270627421637063, 'colsample_bytree': 0.5008284044744004}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:30,649] Trial 18 finished with value: 0.29302847064751847 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.05511238431857829, 'subsample': 0.8445779114924312, 'colsample_bytree': 0.6703690344652179}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:30,716] Trial 19 finished with value: 0.3627540761859317 and parameters: {'n_estimators': 58, 'max_depth': 9, 'learning_rate': 0.11780146270112259, 'subsample': 0.5054945946218856, 'colsample_bytree': 0.6149989317128577}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:30,815] Trial 20 finished with value: 0.3926518014613253 and parameters: {'n_estimators': 116, 'max_depth': 6, 'learning_rate': 0.051059430079181845, 'subsample': 0.942608049397903, 'colsample_bytree': 0.5499997171963321}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:30,949] Trial 21 finished with value: 0.40052343159486015 and parameters: {'n_estimators': 162, 'max_depth': 7, 'learning_rate': 0.011358681404389923, 'subsample': 0.9202685958641561, 'colsample_bytree': 0.5045775502136167}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,060] Trial 22 finished with value: 0.40139933289358576 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.013821972170467822, 'subsample': 0.9397287745118398, 'colsample_bytree': 0.5492229999946834}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,198] Trial 23 finished with value: 0.36970269589317206 and parameters: {'n_estimators': 185, 'max_depth': 9, 'learning_rate': 0.04212592430788528, 'subsample': 0.9990690628061121, 'colsample_bytree': 0.5563201769185298}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,312] Trial 24 finished with value: 0.3398488284202571 and parameters: {'n_estimators': 156, 'max_depth': 7, 'learning_rate': 0.0662579623796048, 'subsample': 0.8619643726697067, 'colsample_bytree': 0.6106994349909649}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,401] Trial 25 finished with value: 0.40876165280927157 and parameters: {'n_estimators': 107, 'max_depth': 5, 'learning_rate': 0.03616137779977861, 'subsample': 0.9450489065892207, 'colsample_bytree': 0.5268268222952215}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,485] Trial 26 finished with value: 0.4265748208066622 and parameters: {'n_estimators': 76, 'max_depth': 9, 'learning_rate': 0.0334104823817237, 'subsample': 0.8751437537599874, 'colsample_bytree': 0.5354921959580827}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,563] Trial 27 finished with value: 0.3586192995716805 and parameters: {'n_estimators': 74, 'max_depth': 9, 'learning_rate': 0.06921306604451469, 'subsample': 0.8716808757116626, 'colsample_bytree': 0.5821474801463692}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,643] Trial 28 finished with value: 0.4183257747543462 and parameters: {'n_estimators': 71, 'max_depth': 8, 'learning_rate': 0.0360543144339434, 'subsample': 0.9545696126535662, 'colsample_bytree': 0.538817874703942}. Best is trial 17 with value: 0.4412058272567304.\n",
      "[I 2025-07-03 10:17:31,713] Trial 29 finished with value: 0.3601196775006298 and parameters: {'n_estimators': 68, 'max_depth': 10, 'learning_rate': 0.13346353279809836, 'subsample': 0.831208220826346, 'colsample_bytree': 0.5917608667900944}. Best is trial 17 with value: 0.4412058272567304.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.706\n",
      "Sensitivity: 0.750\n",
      "Specificity: 0.667\n",
      "AUROC: 0.770\n",
      "F1 Score: 0.706\n",
      "AUPR: 0.802\n",
      "PPV: 0.667\n",
      "NPV: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:31,947] A new study created in memory with name: no-name-99668d68-1c87-464a-bedd-10bbe71bc938\n",
      "[I 2025-07-03 10:17:32,081] Trial 0 finished with value: 0.26904761904761887 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.26904761904761887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xgb_Halm's_and_labs_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:32,177] Trial 1 finished with value: 0.25366717057193255 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 0 with value: 0.26904761904761887.\n",
      "[I 2025-07-03 10:17:32,257] Trial 2 finished with value: 0.3781368102796675 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 2 with value: 0.3781368102796675.\n",
      "[I 2025-07-03 10:17:32,365] Trial 3 finished with value: 0.3301612496850591 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 2 with value: 0.3781368102796675.\n",
      "[I 2025-07-03 10:17:32,543] Trial 4 finished with value: 0.2644406651549508 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 2 with value: 0.3781368102796675.\n",
      "[I 2025-07-03 10:17:32,726] Trial 5 finished with value: 0.2584971025447217 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 2 with value: 0.3781368102796675.\n",
      "[I 2025-07-03 10:17:32,963] Trial 6 finished with value: 0.3172222222222222 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 2 with value: 0.3781368102796675.\n",
      "[I 2025-07-03 10:17:33,232] Trial 7 finished with value: 0.2809347442680775 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 2 with value: 0.3781368102796675.\n",
      "[I 2025-07-03 10:17:33,375] Trial 8 finished with value: 0.4084482206234117 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:33,543] Trial 9 finished with value: 0.31477828168304345 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:33,766] Trial 10 finished with value: 0.38461703199798414 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:33,977] Trial 11 finished with value: 0.39210128495842766 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:34,137] Trial 12 finished with value: 0.3110657596371881 and parameters: {'n_estimators': 138, 'max_depth': 7, 'learning_rate': 0.07437273677969344, 'subsample': 0.909559082329987, 'colsample_bytree': 0.5083811619627875}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:34,275] Trial 13 finished with value: 0.33377299067775257 and parameters: {'n_estimators': 92, 'max_depth': 6, 'learning_rate': 0.07317753931253784, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.6815414005207046}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:34,413] Trial 14 finished with value: 0.38028230359359094 and parameters: {'n_estimators': 65, 'max_depth': 8, 'learning_rate': 0.015439239864582342, 'subsample': 0.9771884962395786, 'colsample_bytree': 0.6475112154932409}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:34,644] Trial 15 finished with value: 0.2852280171327791 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.10941179359723172, 'subsample': 0.8860415177204133, 'colsample_bytree': 0.5772775206570726}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:34,818] Trial 16 finished with value: 0.3281695641219452 and parameters: {'n_estimators': 123, 'max_depth': 8, 'learning_rate': 0.054627383778403316, 'subsample': 0.9982314822718655, 'colsample_bytree': 0.6396628859709779}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:35,071] Trial 17 finished with value: 0.37655756495556625 and parameters: {'n_estimators': 165, 'max_depth': 5, 'learning_rate': 0.011970005553332302, 'subsample': 0.8625194298037667, 'colsample_bytree': 0.7886325014676998}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:35,234] Trial 18 finished with value: 0.3449937011841774 and parameters: {'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.055798510544807056, 'subsample': 0.9334611162815576, 'colsample_bytree': 0.5557525407611206}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:35,398] Trial 19 finished with value: 0.29450491307634186 and parameters: {'n_estimators': 176, 'max_depth': 9, 'learning_rate': 0.09537368342846862, 'subsample': 0.5054945946218856, 'colsample_bytree': 0.5041143164204508}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:35,537] Trial 20 finished with value: 0.36423784328546216 and parameters: {'n_estimators': 81, 'max_depth': 7, 'learning_rate': 0.04469131225419362, 'subsample': 0.9417045751910271, 'colsample_bytree': 0.5474863513918804}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:35,779] Trial 21 finished with value: 0.4028231292517005 and parameters: {'n_estimators': 161, 'max_depth': 7, 'learning_rate': 0.010595466293421557, 'subsample': 0.9779294005085005, 'colsample_bytree': 0.5057580958976077}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:35,993] Trial 22 finished with value: 0.34183673469387765 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.0330300367187072, 'subsample': 0.943760846963732, 'colsample_bytree': 0.6095638097983449}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:36,176] Trial 23 finished with value: 0.3930032753842275 and parameters: {'n_estimators': 109, 'max_depth': 6, 'learning_rate': 0.011328298006558475, 'subsample': 0.999600485967525, 'colsample_bytree': 0.5327155559343973}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:36,325] Trial 24 finished with value: 0.36217183169564116 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.06010744494751776, 'subsample': 0.8684763819471241, 'colsample_bytree': 0.5552816872312777}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:36,447] Trial 25 finished with value: 0.3886772486772486 and parameters: {'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.0384693912482143, 'subsample': 0.9395903404957827, 'colsample_bytree': 0.5450870264737138}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:36,580] Trial 26 finished with value: 0.3405429579239104 and parameters: {'n_estimators': 107, 'max_depth': 9, 'learning_rate': 0.12011652765932022, 'subsample': 0.8978831407027816, 'colsample_bytree': 0.6157252586868023}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:36,754] Trial 27 finished with value: 0.3586747291509197 and parameters: {'n_estimators': 156, 'max_depth': 5, 'learning_rate': 0.0694415186095841, 'subsample': 0.9996606135859452, 'colsample_bytree': 0.5535252274339282}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:36,931] Trial 28 finished with value: 0.36340136054421757 and parameters: {'n_estimators': 124, 'max_depth': 6, 'learning_rate': 0.03338973327709835, 'subsample': 0.8435613207530962, 'colsample_bytree': 0.6098437508687804}. Best is trial 8 with value: 0.4084482206234117.\n",
      "[I 2025-07-03 10:17:37,027] Trial 29 finished with value: 0.3250226757369613 and parameters: {'n_estimators': 70, 'max_depth': 7, 'learning_rate': 0.2945807951599052, 'subsample': 0.9433988191621602, 'colsample_bytree': 0.5788450326337377}. Best is trial 8 with value: 0.4084482206234117.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.569\n",
      "Sensitivity: 0.625\n",
      "Specificity: 0.519\n",
      "AUROC: 0.724\n",
      "F1 Score: 0.577\n",
      "AUPR: 0.778\n",
      "PPV: 0.536\n",
      "NPV: 0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:37,361] A new study created in memory with name: no-name-8dabfa98-e2d3-4314-97d0-6c800fe06c67\n",
      "[I 2025-07-03 10:17:37,454] Trial 0 finished with value: 0.23913580246913557 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.23913580246913557.\n",
      "[I 2025-07-03 10:17:37,517] Trial 1 finished with value: 0.3669211388259005 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 1 with value: 0.3669211388259005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xgb_Halm's_and_ventilator_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:37,574] Trial 2 finished with value: 0.3244721592340639 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 1 with value: 0.3669211388259005.\n",
      "[I 2025-07-03 10:17:37,649] Trial 3 finished with value: 0.35664399092970533 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 1 with value: 0.3669211388259005.\n",
      "[I 2025-07-03 10:17:37,770] Trial 4 finished with value: 0.337867220962459 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 1 with value: 0.3669211388259005.\n",
      "[I 2025-07-03 10:17:37,898] Trial 5 finished with value: 0.30284706475182677 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 1 with value: 0.3669211388259005.\n",
      "[I 2025-07-03 10:17:38,044] Trial 6 finished with value: 0.33819626799050684 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 1 with value: 0.3669211388259005.\n",
      "[I 2025-07-03 10:17:38,217] Trial 7 finished with value: 0.3597933988410179 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 1 with value: 0.3669211388259005.\n",
      "[I 2025-07-03 10:17:38,308] Trial 8 finished with value: 0.4467331697196484 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.4467331697196484.\n",
      "[I 2025-07-03 10:17:38,429] Trial 9 finished with value: 0.33604560342655565 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.4467331697196484.\n",
      "[I 2025-07-03 10:17:38,577] Trial 10 finished with value: 0.4394787068919932 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 8 with value: 0.4467331697196484.\n",
      "[I 2025-07-03 10:17:38,718] Trial 11 finished with value: 0.42006701628982634 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 8 with value: 0.4467331697196484.\n",
      "[I 2025-07-03 10:17:38,843] Trial 12 finished with value: 0.3619639707734946 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.07437273677969344, 'subsample': 0.9064336124353589, 'colsample_bytree': 0.661718184034389}. Best is trial 8 with value: 0.4467331697196484.\n",
      "[I 2025-07-03 10:17:38,937] Trial 13 finished with value: 0.39999874023683535 and parameters: {'n_estimators': 93, 'max_depth': 6, 'learning_rate': 0.07317753931253784, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.501840856025911}. Best is trial 8 with value: 0.4467331697196484.\n",
      "[I 2025-07-03 10:17:39,028] Trial 14 finished with value: 0.46479537464404397 and parameters: {'n_estimators': 65, 'max_depth': 8, 'learning_rate': 0.015383461018707016, 'subsample': 0.905739014043769, 'colsample_bytree': 0.6526674440760509}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,107] Trial 15 finished with value: 0.3681960191484003 and parameters: {'n_estimators': 58, 'max_depth': 9, 'learning_rate': 0.10941179359723172, 'subsample': 0.8859333339419407, 'colsample_bytree': 0.7996707542721728}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,315] Trial 16 finished with value: 0.33275006298815824 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.04876728016098438, 'subsample': 0.8630258032024203, 'colsample_bytree': 0.6570925069581378}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,433] Trial 17 finished with value: 0.402663139329806 and parameters: {'n_estimators': 115, 'max_depth': 6, 'learning_rate': 0.05622641632241577, 'subsample': 0.9270627421637063, 'colsample_bytree': 0.6866291716128416}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,515] Trial 18 finished with value: 0.36428445452254976 and parameters: {'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.11766738001065247, 'subsample': 0.9362846919714561, 'colsample_bytree': 0.7751411631697382}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,661] Trial 19 finished with value: 0.37563450005380716 and parameters: {'n_estimators': 171, 'max_depth': 8, 'learning_rate': 0.01073932434882729, 'subsample': 0.5054945946218856, 'colsample_bytree': 0.619350988480298}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,773] Trial 20 finished with value: 0.3767309145880574 and parameters: {'n_estimators': 115, 'max_depth': 5, 'learning_rate': 0.051059430079181845, 'subsample': 0.862164016276298, 'colsample_bytree': 0.7005883113475668}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,876] Trial 21 finished with value: 0.4231473860691969 and parameters: {'n_estimators': 79, 'max_depth': 8, 'learning_rate': 0.010614528417379731, 'subsample': 0.9865399030157589, 'colsample_bytree': 0.5575483328315063}. Best is trial 14 with value: 0.46479537464404397.\n",
      "[I 2025-07-03 10:17:39,951] Trial 22 finished with value: 0.4870324956685922 and parameters: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.034286505611841545, 'subsample': 0.9563361565842547, 'colsample_bytree': 0.5492229999946834}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,030] Trial 23 finished with value: 0.47056966179247195 and parameters: {'n_estimators': 51, 'max_depth': 9, 'learning_rate': 0.04145098319643249, 'subsample': 0.9396156962797074, 'colsample_bytree': 0.621632256133405}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,108] Trial 24 finished with value: 0.43887125220458556 and parameters: {'n_estimators': 59, 'max_depth': 9, 'learning_rate': 0.06877395343577317, 'subsample': 0.8979338809467867, 'colsample_bytree': 0.5596739448704294}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,185] Trial 25 finished with value: 0.46657293116191534 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.0384693912482143, 'subsample': 0.9410950939846858, 'colsample_bytree': 0.6145777931279819}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,304] Trial 26 finished with value: 0.4172612748803225 and parameters: {'n_estimators': 114, 'max_depth': 9, 'learning_rate': 0.04020718726501653, 'subsample': 0.9397503979440351, 'colsample_bytree': 0.5452118225378322}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,380] Trial 27 finished with value: 0.4338384983623075 and parameters: {'n_estimators': 53, 'max_depth': 10, 'learning_rate': 0.08447522704489344, 'subsample': 0.9993086285459962, 'colsample_bytree': 0.615179993950313}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,487] Trial 28 finished with value: 0.42710002519526336 and parameters: {'n_estimators': 98, 'max_depth': 9, 'learning_rate': 0.05270579430337094, 'subsample': 0.9487356059269232, 'colsample_bytree': 0.5503511924870477}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,591] Trial 29 finished with value: 0.3172612748803224 and parameters: {'n_estimators': 130, 'max_depth': 10, 'learning_rate': 0.1369373722926939, 'subsample': 0.8422641260902025, 'colsample_bytree': 0.5879407524722504}. Best is trial 22 with value: 0.4870324956685922.\n",
      "[I 2025-07-03 10:17:40,766] A new study created in memory with name: no-name-c1adea66-ea8d-4c5e-bed9-1678ec852928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.745\n",
      "Sensitivity: 0.708\n",
      "Specificity: 0.778\n",
      "AUROC: 0.787\n",
      "F1 Score: 0.723\n",
      "AUPR: 0.792\n",
      "PPV: 0.739\n",
      "NPV: 0.750\n",
      "Running xgb_Halm's_and_meds_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:40,854] Trial 0 finished with value: 0.14927941546989165 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.14927941546989165.\n",
      "[I 2025-07-03 10:17:40,914] Trial 1 finished with value: 0.2174565381708239 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 1 with value: 0.2174565381708239.\n",
      "[I 2025-07-03 10:17:40,966] Trial 2 finished with value: 0.2556273620559334 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 2 with value: 0.2556273620559334.\n",
      "[I 2025-07-03 10:17:41,036] Trial 3 finished with value: 0.251410934744268 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 2 with value: 0.2556273620559334.\n",
      "[I 2025-07-03 10:17:41,147] Trial 4 finished with value: 0.25322121441169065 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 2 with value: 0.2556273620559334.\n",
      "[I 2025-07-03 10:17:41,265] Trial 5 finished with value: 0.2293109095490048 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 2 with value: 0.2556273620559334.\n",
      "[I 2025-07-03 10:17:41,387] Trial 6 finished with value: 0.2627256409835623 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 6 with value: 0.2627256409835623.\n",
      "[I 2025-07-03 10:17:41,539] Trial 7 finished with value: 0.22282690854119414 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 6 with value: 0.2627256409835623.\n",
      "[I 2025-07-03 10:17:41,622] Trial 8 finished with value: 0.318627631203094 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.318627631203094.\n",
      "[I 2025-07-03 10:17:41,738] Trial 9 finished with value: 0.21043209876543212 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.318627631203094.\n",
      "[I 2025-07-03 10:17:41,871] Trial 10 finished with value: 0.3302525825144872 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,004] Trial 11 finished with value: 0.32334215167548475 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,118] Trial 12 finished with value: 0.28983623078861187 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.07568854089179115, 'subsample': 0.9959735872518112, 'colsample_bytree': 0.5082196100884397}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,253] Trial 13 finished with value: 0.30093096497858396 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.012268998021885573, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.5017435095529454}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,360] Trial 14 finished with value: 0.25566893424036274 and parameters: {'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.07871338854502816, 'subsample': 0.8947385331597324, 'colsample_bytree': 0.6738167152482915}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,522] Trial 15 finished with value: 0.23903250188964476 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.10941179359723172, 'subsample': 0.8983037533293151, 'colsample_bytree': 0.551391132130877}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,659] Trial 16 finished with value: 0.28926429831191747 and parameters: {'n_estimators': 172, 'max_depth': 8, 'learning_rate': 0.051236385539058536, 'subsample': 0.9982492789189122, 'colsample_bytree': 0.5666808587565859}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,787] Trial 17 finished with value: 0.2545641219450744 and parameters: {'n_estimators': 167, 'max_depth': 7, 'learning_rate': 0.06214586302739612, 'subsample': 0.933206128098298, 'colsample_bytree': 0.5008292380436842}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,877] Trial 18 finished with value: 0.24593852355757118 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.11561628723488286, 'subsample': 0.8563747806608468, 'colsample_bytree': 0.6709736322811276}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:42,998] Trial 19 finished with value: 0.3195312626378022 and parameters: {'n_estimators': 116, 'max_depth': 9, 'learning_rate': 0.010512481894717743, 'subsample': 0.9441090577556688, 'colsample_bytree': 0.6149989317128577}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:43,137] Trial 20 finished with value: 0.2712887377173091 and parameters: {'n_estimators': 191, 'max_depth': 6, 'learning_rate': 0.04682040893725792, 'subsample': 0.8687393823928287, 'colsample_bytree': 0.5499997171963321}. Best is trial 10 with value: 0.3302525825144872.\n",
      "[I 2025-07-03 10:17:43,257] Trial 21 finished with value: 0.33743866403042555 and parameters: {'n_estimators': 119, 'max_depth': 9, 'learning_rate': 0.010574047600146162, 'subsample': 0.946244362603164, 'colsample_bytree': 0.606315181465154}. Best is trial 21 with value: 0.33743866403042555.\n",
      "[I 2025-07-03 10:17:43,373] Trial 22 finished with value: 0.30292768959435634 and parameters: {'n_estimators': 121, 'max_depth': 9, 'learning_rate': 0.03302461938392429, 'subsample': 0.948737402591358, 'colsample_bytree': 0.5492229999946834}. Best is trial 21 with value: 0.33743866403042555.\n",
      "[I 2025-07-03 10:17:43,521] Trial 23 finished with value: 0.34644368858654584 and parameters: {'n_estimators': 158, 'max_depth': 7, 'learning_rate': 0.011327910473183704, 'subsample': 0.999600485967525, 'colsample_bytree': 0.5532131040833295}. Best is trial 23 with value: 0.34644368858654584.\n",
      "[I 2025-07-03 10:17:43,655] Trial 24 finished with value: 0.26021415973796913 and parameters: {'n_estimators': 165, 'max_depth': 9, 'learning_rate': 0.056586732648154205, 'subsample': 0.9225739591072, 'colsample_bytree': 0.618433733659315}. Best is trial 23 with value: 0.34644368858654584.\n",
      "[I 2025-07-03 10:17:43,736] Trial 25 finished with value: 0.3326769967246158 and parameters: {'n_estimators': 60, 'max_depth': 7, 'learning_rate': 0.03853937125489776, 'subsample': 0.9634214648396023, 'colsample_bytree': 0.5502225079313358}. Best is trial 23 with value: 0.34644368858654584.\n",
      "[I 2025-07-03 10:17:43,806] Trial 26 finished with value: 0.3138145810344215 and parameters: {'n_estimators': 55, 'max_depth': 5, 'learning_rate': 0.04040096276797979, 'subsample': 0.8824258142702299, 'colsample_bytree': 0.6044084624435483}. Best is trial 23 with value: 0.34644368858654584.\n",
      "[I 2025-07-03 10:17:43,894] Trial 27 finished with value: 0.2629680020156212 and parameters: {'n_estimators': 75, 'max_depth': 8, 'learning_rate': 0.06921306604451469, 'subsample': 0.9317443028658455, 'colsample_bytree': 0.653910938017115}. Best is trial 23 with value: 0.34644368858654584.\n",
      "[I 2025-07-03 10:17:43,983] Trial 28 finished with value: 0.28679390274628347 and parameters: {'n_estimators': 71, 'max_depth': 9, 'learning_rate': 0.03541160043460684, 'subsample': 0.8448293760495029, 'colsample_bytree': 0.5676257389401568}. Best is trial 23 with value: 0.34644368858654584.\n",
      "[I 2025-07-03 10:17:44,066] Trial 29 finished with value: 0.27323759133282943 and parameters: {'n_estimators': 109, 'max_depth': 10, 'learning_rate': 0.2945807951599052, 'subsample': 0.9538686072652311, 'colsample_bytree': 0.576125040988762}. Best is trial 23 with value: 0.34644368858654584.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.686\n",
      "Sensitivity: 0.750\n",
      "Specificity: 0.630\n",
      "AUROC: 0.759\n",
      "F1 Score: 0.692\n",
      "AUPR: 0.792\n",
      "PPV: 0.643\n",
      "NPV: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:44,396] A new study created in memory with name: no-name-390e721f-4535-4f1c-9bdc-c6b389b9d40a\n",
      "[I 2025-07-03 10:17:44,544] Trial 0 finished with value: 0.23779037540942294 and parameters: {'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.22227824312530747, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182}. Best is trial 0 with value: 0.23779037540942294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running xgb_Halm's_and_labs_meds_and_ventilator_features (XGBoost)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 10:17:44,656] Trial 1 finished with value: 0.25841773746535635 and parameters: {'n_estimators': 89, 'max_depth': 2, 'learning_rate': 0.2611910822747312, 'subsample': 0.8005575058716043, 'colsample_bytree': 0.8540362888980227}. Best is trial 1 with value: 0.25841773746535635.\n",
      "[I 2025-07-03 10:17:44,747] Trial 2 finished with value: 0.2769110607205846 and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.2514083658321223, 'subsample': 0.6061695553391381, 'colsample_bytree': 0.5909124836035503}. Best is trial 2 with value: 0.2769110607205846.\n",
      "[I 2025-07-03 10:17:44,871] Trial 3 finished with value: 0.2982224741748548 and parameters: {'n_estimators': 96, 'max_depth': 4, 'learning_rate': 0.16217936517334897, 'subsample': 0.7159725093210578, 'colsample_bytree': 0.645614570099021}. Best is trial 3 with value: 0.2982224741748548.\n",
      "[I 2025-07-03 10:17:45,077] Trial 4 finished with value: 0.2513807004283194 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.09472194807521325, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518}. Best is trial 3 with value: 0.2982224741748548.\n",
      "[I 2025-07-03 10:17:45,284] Trial 5 finished with value: 0.2815016376921141 and parameters: {'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.15912798713994736, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989}. Best is trial 3 with value: 0.2982224741748548.\n",
      "[I 2025-07-03 10:17:45,555] Trial 6 finished with value: 0.27820609725371626 and parameters: {'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.02886496196573106, 'subsample': 0.9744427686266666, 'colsample_bytree': 0.9828160165372797}. Best is trial 3 with value: 0.2982224741748548.\n",
      "[I 2025-07-03 10:17:45,861] Trial 7 finished with value: 0.29648904006046883 and parameters: {'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.03832491306185132, 'subsample': 0.8421165132560784, 'colsample_bytree': 0.7200762468698007}. Best is trial 3 with value: 0.2982224741748548.\n",
      "[I 2025-07-03 10:17:46,028] Trial 8 finished with value: 0.3208543682676548 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.019972671123413333, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085}. Best is trial 8 with value: 0.3208543682676548.\n",
      "[I 2025-07-03 10:17:46,228] Trial 9 finished with value: 0.2537389770723103 and parameters: {'n_estimators': 216, 'max_depth': 4, 'learning_rate': 0.16081972614156514, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636}. Best is trial 8 with value: 0.3208543682676548.\n",
      "[I 2025-07-03 10:17:46,492] Trial 10 finished with value: 0.3513303099017385 and parameters: {'n_estimators': 144, 'max_depth': 7, 'learning_rate': 0.012188722601725016, 'subsample': 0.9774843668999692, 'colsample_bytree': 0.5103029850474143}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:46,750] Trial 11 finished with value: 0.3450768455530361 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.013153960521410067, 'subsample': 0.9850248734594017, 'colsample_bytree': 0.5019007264810743}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:46,948] Trial 12 finished with value: 0.32198412698412715 and parameters: {'n_estimators': 138, 'max_depth': 8, 'learning_rate': 0.07568854089179115, 'subsample': 0.9959735872518112, 'colsample_bytree': 0.5082196100884397}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:47,213] Trial 13 finished with value: 0.3435563114134542 and parameters: {'n_estimators': 147, 'max_depth': 7, 'learning_rate': 0.012268998021885573, 'subsample': 0.9112320253004818, 'colsample_bytree': 0.5017435095529454}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:47,406] Trial 14 finished with value: 0.26624716553287964 and parameters: {'n_estimators': 122, 'max_depth': 8, 'learning_rate': 0.07871338854502816, 'subsample': 0.8947385331597324, 'colsample_bytree': 0.6738167152482915}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:47,680] Trial 15 finished with value: 0.24772864701436104 and parameters: {'n_estimators': 292, 'max_depth': 6, 'learning_rate': 0.10941179359723172, 'subsample': 0.8983037533293151, 'colsample_bytree': 0.551391132130877}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:47,929] Trial 16 finished with value: 0.3195679012345679 and parameters: {'n_estimators': 172, 'max_depth': 8, 'learning_rate': 0.051236385539058536, 'subsample': 0.9982492789189122, 'colsample_bytree': 0.5666808587565859}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:48,154] Trial 17 finished with value: 0.27484001007810555 and parameters: {'n_estimators': 167, 'max_depth': 7, 'learning_rate': 0.06214586302739612, 'subsample': 0.933206128098298, 'colsample_bytree': 0.5008292380436842}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:48,323] Trial 18 finished with value: 0.27172713529856385 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.11561628723488286, 'subsample': 0.8563747806608468, 'colsample_bytree': 0.6709736322811276}. Best is trial 10 with value: 0.3513303099017385.\n",
      "[I 2025-07-03 10:17:48,575] Trial 19 finished with value: 0.371503146297385 and parameters: {'n_estimators': 116, 'max_depth': 9, 'learning_rate': 0.010512481894717743, 'subsample': 0.9441090577556688, 'colsample_bytree': 0.6149989317128577}. Best is trial 19 with value: 0.371503146297385.\n",
      "[I 2025-07-03 10:17:48,780] Trial 20 finished with value: 0.3066402116402117 and parameters: {'n_estimators': 116, 'max_depth': 9, 'learning_rate': 0.051059430079181845, 'subsample': 0.9346889183672964, 'colsample_bytree': 0.617548131626509}. Best is trial 19 with value: 0.371503146297385.\n",
      "[I 2025-07-03 10:17:48,925] Trial 21 finished with value: 0.3923543651571283 and parameters: {'n_estimators': 58, 'max_depth': 9, 'learning_rate': 0.010574047600146162, 'subsample': 0.9580998194020144, 'colsample_bytree': 0.546339729257732}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:49,056] Trial 22 finished with value: 0.35320987654321 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.04095516438525981, 'subsample': 0.8704626963258232, 'colsample_bytree': 0.5492229999946834}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:49,187] Trial 23 finished with value: 0.36457168052406164 and parameters: {'n_estimators': 51, 'max_depth': 9, 'learning_rate': 0.04190425699821465, 'subsample': 0.8601210547245456, 'colsample_bytree': 0.575563543429626}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:49,349] Trial 24 finished with value: 0.3164222726127487 and parameters: {'n_estimators': 71, 'max_depth': 9, 'learning_rate': 0.036550346755387424, 'subsample': 0.9190552776064272, 'colsample_bytree': 0.6104361210965896}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:49,494] Trial 25 finished with value: 0.3236344167296551 and parameters: {'n_estimators': 67, 'max_depth': 10, 'learning_rate': 0.05943377077431278, 'subsample': 0.8576849886455052, 'colsample_bytree': 0.5531897684265306}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:49,717] Trial 26 finished with value: 0.32126228269085433 and parameters: {'n_estimators': 111, 'max_depth': 9, 'learning_rate': 0.032981928011949664, 'subsample': 0.9441797002921648, 'colsample_bytree': 0.6505152466626336}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:49,864] Trial 27 finished with value: 0.3506941295036533 and parameters: {'n_estimators': 69, 'max_depth': 8, 'learning_rate': 0.06921306604451469, 'subsample': 0.8859109933272076, 'colsample_bytree': 0.6044870183240054}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:50,000] Trial 28 finished with value: 0.36913101225858425 and parameters: {'n_estimators': 53, 'max_depth': 10, 'learning_rate': 0.035205862274781355, 'subsample': 0.8286668574234219, 'colsample_bytree': 0.6969228536235459}. Best is trial 21 with value: 0.3923543651571283.\n",
      "[I 2025-07-03 10:17:50,123] Trial 29 finished with value: 0.22143487024439412 and parameters: {'n_estimators': 87, 'max_depth': 10, 'learning_rate': 0.2945807951599052, 'subsample': 0.8168624214107696, 'colsample_bytree': 0.6907670542494438}. Best is trial 21 with value: 0.3923543651571283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.706\n",
      "Sensitivity: 0.792\n",
      "Specificity: 0.630\n",
      "AUROC: 0.790\n",
      "F1 Score: 0.717\n",
      "AUPR: 0.799\n",
      "PPV: 0.655\n",
      "NPV: 0.773\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a copy\n",
    "df = cap_1to3_sub.copy()\n",
    "\n",
    "# 2. train/test split\n",
    "unique_pt_ids = df['pt_study_id'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_pt_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = df['pt_study_id'].isin(train_ids)\n",
    "test_mask = df['pt_study_id'].isin(test_ids)\n",
    "\n",
    "train =df[train_mask].copy()\n",
    "test = df[test_mask].copy()\n",
    "\n",
    "print(\"Number of episodes:\")\n",
    "print(f\"Train: {train['episode_id'].nunique()}, Test: {test['episode_id'].nunique()}\")\n",
    "print(\"Number of unique patients:\")\n",
    "print(f\"Train: {train['pt_study_id'].nunique()}, Test: {test['pt_study_id'].nunique()}\")\n",
    "\n",
    "# 3. Run models\n",
    "# get X_train, X_test, y_train, y_test\n",
    "X_train = train.drop(columns=['pt_study_id', 'd7_episode_resolution_binary', 'episode_id'])\n",
    "X_test = test.drop(columns=['pt_study_id', 'd7_episode_resolution_binary', 'episode_id'])\n",
    "y_train = train['d7_episode_resolution_binary'].copy()\n",
    "y_test = test['d7_episode_resolution_binary'].copy()\n",
    "\n",
    "pt_ids_train = train['pt_study_id'].copy()\n",
    "\n",
    "for model_name, feature_cols in feature_sets.items():\n",
    "    available_features = [c for c in feature_cols if c not in ['pt_study_id', 'd7_episode_resolution_binary', 'episode_id']]\n",
    "    full_model_name = f\"xgb_{model_name}\"\n",
    "    X_train_sub = X_train[available_features].copy()\n",
    "    X_test_sub = X_test[available_features].copy()\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"Running {full_model_name} (XGBoost)...\")\n",
    "    name, result = run_xgb_model_pipeline(\n",
    "        model_name=full_model_name,\n",
    "        X_train=X_train_sub,\n",
    "        X_test=X_test_sub,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        pt_ids_train=pt_ids_train,\n",
    "        n_trials=30,\n",
    "        n_splits=10,\n",
    "        random_state=42,\n",
    "        threshold=0.5,\n",
    "        plot_sp=False,\n",
    "        max_display=10\n",
    "    )\n",
    "\n",
    "    results[full_model_name] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Performance (Median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename model names\n",
    "model_rename = {\n",
    "    'xgb_Halm\\'s_and_labs_meds_and_ventilator_features': 'Halm\\'s Features with \\nLabs, Ventilator,\\nand Medication Features',\n",
    "    'xgb_Halm\\'s_and_meds_features': 'Halm\\'s Features with\\nMedication Features',\n",
    "    'xgb_Halm\\'s_and_ventilator_features': 'Halm\\'s Features with\\nVentilator Features',\n",
    "    'xgb_Halm\\'s_and_labs_features': 'Halm\\'s Features with\\nLabs Features',\n",
    "    'xgb_avg_and_worst_Halm\\'s_features': 'Avg and\\nWorst Halm\\'s Features',\n",
    "    'xgb_worst_Halm\\'s_features': 'Worst Halm\\'s Features',\n",
    "    'xgb_avg_Halm\\'s_features': 'Avg Halm\\'s Features'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/flfk9jd16tv0pc1fnh97zcmc0000gp/T/ipykernel_1139/516282652.py:59: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"o\" (-> marker='o'). The keyword argument will take precedence.\n",
      "  plt.errorbar(\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "model_keys = [k for k in model_rename.keys() if k in results]\n",
    "scores = [results[k]['cv_results']['aurocs'] for k in model_keys]\n",
    "\n",
    "# get renamed x-labels\n",
    "model_names = [model_rename[k] for k in model_keys]\n",
    "\n",
    "x = np.arange(1, len(model_names) + 1)\n",
    "\n",
    "#### --- BOX PLOT (median/IQR) + scatter --- ####\n",
    "boxplot_file = os.path.join(output_path, 'model_performance_boxplot')\n",
    "\n",
    "plt.figure(figsize=(max(10, len(model_names)*1.5), 6))\n",
    "box = plt.boxplot(\n",
    "        scores,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor=\"lightblue\", color=\"black\"),\n",
    "        showfliers=False,\n",
    "        medianprops=dict(color=\"red\"),\n",
    "        whiskerprops=dict(color=\"black\"),\n",
    "        capprops=dict(color=\"black\"),\n",
    "        flierprops=dict(markerfacecolor='gray', marker='o', markersize=5, linestyle='none')\n",
    "    )\n",
    "# Add scatter points (jittered)\n",
    "for j, ss in enumerate(scores):\n",
    "    x_jitter = np.random.normal(loc=x[j], scale=0.05, size=len(ss))\n",
    "    plt.scatter(x_jitter, ss, color=\"black\", alpha=0.7, zorder=3)\n",
    "\n",
    "for i, median_line in enumerate(box['medians']):\n",
    "    x_median, y_median = median_line.get_xdata()[1], median_line.get_ydata()[1]\n",
    "    median_val = np.median(scores[i])\n",
    "    plt.text(\n",
    "        x_median + 0.03, y_median,\n",
    "        f\"{median_val:.3f}\",\n",
    "        va='center', ha='left',\n",
    "        fontsize=10, color='red',\n",
    "        bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=0.1)\n",
    "    )\n",
    "\n",
    "plt.title(\"Model Performance: AUROC (10-Fold CV  STD)\", fontsize=15)\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.xticks(ticks=x, labels=model_names, rotation=45, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{boxplot_file}.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.savefig(f\"{boxplot_file}.png\", bbox_inches='tight', dpi=300)\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "#### --- MEAN  SD PLOT + scatter --- ####\n",
    "meanplot_file = os.path.join(output_path, 'model_performance_mean_sd')\n",
    "\n",
    "means = [np.mean(s) for s in scores]\n",
    "stds = [np.std(s) for s in scores]\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.errorbar(\n",
    "    means, x, xerr=stds, fmt='o', color='black',\n",
    "    ecolor='black', elinewidth=2, capsize=6,\n",
    "    markerfacecolor='grey', markeredgewidth=1.5, marker='o', markersize=10\n",
    ")\n",
    "\n",
    "# Add data points\n",
    "for j, ss in enumerate(scores):\n",
    "    y_jitter = np.random.normal(loc=x[j], scale=0.04, size=len(ss))\n",
    "    plt.scatter(ss, y_jitter, color=\"darkgray\", alpha=0.7, s=18, zorder=2)\n",
    "\n",
    "for j, (mean, xj) in enumerate(zip(means, x)):\n",
    "    plt.text(\n",
    "        mean, xj - 0.15,\n",
    "        f\"{mean:.3f}\",\n",
    "        va='top', ha='center',\n",
    "        fontsize=16, color='black', fontweight='bold',\n",
    "        bbox=dict(facecolor='white', edgecolor='none', alpha=0.7, pad=0.1)\n",
    "    )\n",
    "\n",
    "plt.title(\"Model Performance: AUROC (10-Fold Cross-Validation, Mean  SD)\", fontsize=18)\n",
    "plt.xlabel(\"AUROC\", fontsize=15)\n",
    "plt.xlim(0.3, 1.0)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(ticks=x, labels=model_names, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{meanplot_file}.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.savefig(f\"{meanplot_file}.png\", bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Performance (AUROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = ['xgb_worst_Halm\\'s_features']\n",
    "group2 = ['xgb_Halm\\'s_and_ventilator_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(models_to_plot, results, title, ax=None, ci_alpha=0.2, show_yaxis=True):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    for model_name in models_to_plot:\n",
    "        if model_name not in results:\n",
    "            continue\n",
    "        model_results = results[model_name]\n",
    "        \n",
    "        if model_name.startswith(\"logreg\"):\n",
    "            model_type = 'Logistic Regression'\n",
    "            color_cv = 'blue'\n",
    "            color_test = 'red'\n",
    "        elif model_name.startswith(\"xgb\"):\n",
    "            model_type = 'XGBoost'\n",
    "            color_cv = 'green'  \n",
    "            color_test = 'orange' \n",
    "        elif 'baseline' in model_name.lower():\n",
    "            model_type = \"Halm's Criteria\"\n",
    "            color_cv = 'gray'\n",
    "            color_test = 'black'\n",
    "        else:\n",
    "            model_type = model_name.replace('_', ' ').title()\n",
    "            color_cv = 'black'\n",
    "            color_test = 'black'\n",
    "\n",
    "\n",
    "        # Plot ML models with CV\n",
    "        if all(k in model_results for k in ['test_pred', 'y_test', 'cv_results']) and model_results['cv_results'] is not None:\n",
    "            y_test = model_results['y_test']\n",
    "            y_score_test = model_results.get('test_pred_prob', model_results['test_pred'])\n",
    "            mean_fpr = model_results['cv_results']['mean_fpr']\n",
    "            mean_tpr = model_results['cv_results']['mean_tpr']\n",
    "            cv_aucs = model_results['cv_results']['aurocs']\n",
    "            mean_auc = auc(mean_fpr, mean_tpr)\n",
    "            std_auc = np.std(cv_aucs)\n",
    "\n",
    "            # --- Confidence Interval ---\n",
    "            if 'std_tpr' in model_results['cv_results']:\n",
    "                std_tpr = model_results['cv_results']['std_tpr']\n",
    "                upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "                lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "                ax.fill_between(mean_fpr, lower, upper, color=color_cv, alpha=ci_alpha)\n",
    "\n",
    "            \n",
    "            # Plot mean CV ROC\n",
    "            ax.plot(mean_fpr, mean_tpr, lw=2, color=color_cv,\n",
    "                    label=f\"{model_type} CV (AUROC = {mean_auc:.3f}  {std_auc:.3f})\")\n",
    "            # Plot test ROC\n",
    "            fpr_test, tpr_test, _ = roc_curve(y_test.astype(int), y_score_test)\n",
    "            auc_test = roc_auc_score(y_test, y_score_test)\n",
    "            ax.plot(fpr_test, tpr_test, lw=2, color=color_test,\n",
    "                    label=f\"{model_type} Test (AUROC = {auc_test:.3f})\")\n",
    "            \n",
    "            \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1)\n",
    "    ax.set_xlabel(\"False Positive Rate\", fontsize=16)\n",
    "    ax.set_ylabel(\"True Positive Rate\", fontsize=16)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.legend(loc=\"lower right\", fontsize=15)\n",
    "    ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_path, 'roc_comparison')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=False)\n",
    "\n",
    "plot_roc(group1, results, \"Worst Halm's Features\", ax=ax1, show_yaxis=True)\n",
    "plot_roc(group2, results, \"Worst Halm's Features with Worst Ventilator Features\", ax=ax2, show_yaxis=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{file_path}.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(f'{file_path}.png', bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SHAP plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/flfk9jd16tv0pc1fnh97zcmc0000gp/T/ipykernel_1139/15909787.py:109: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "/var/folders/s6/flfk9jd16tv0pc1fnh97zcmc0000gp/T/ipykernel_1139/15909787.py:109: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n"
     ]
    }
   ],
   "source": [
    "model1 = results['xgb_worst_Halm\\'s_features']['model']\n",
    "data1 = results['xgb_worst_Halm\\'s_features']['X_test']\n",
    "model2 = results['xgb_Halm\\'s_and_ventilator_features']['model']\n",
    "data2 = results['xgb_Halm\\'s_and_ventilator_features']['X_test']\n",
    "\n",
    "plot_shap_customized_axis(model1, data1, 'Worst Halm\\'s Features', plot=True, \n",
    "                                  left_label='Cured Likely',right_label='Cured Unlikely', \n",
    "                                  save_path=os.path.join(output_path, 'xgb_worst_Halms_features_shap.png'))\n",
    "plot_shap_customized_axis(model2, data2, 'Halm\\'s and Ventilator Features', plot=True, \n",
    "                                  left_label='Cured Likely',right_label='Cured Unlikely',\n",
    "                                  save_path=os.path.join(output_path, 'xgb_Halms_and_vents_features.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Table one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of column with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# create summary tables for during CAP episode\n",
    "crrt_flag_positive = cap.groupby(['pt_study_id', 'episode_id'])['crrt_flag'].max().reset_index().rename(columns={\"crrt_flag\": \"crrt_flag_positive\"})\n",
    "ecmo_flag_positive = cap.groupby(['pt_study_id', 'episode_id'])['ecmo_flag'].max().reset_index().rename(columns={\"ecmo_flag\": \"ecmo_flag_positive\"})\n",
    "intub_flag_positive = cap.groupby(['pt_study_id', 'episode_id'])['intub_flag'].max().reset_index().rename(columns={\"intub_flag\": \"intub_flag_positive\"})\n",
    "tracheostomy_flag_positive = cap.groupby(['pt_study_id', 'episode_id'])['tracheostomy_flag'].max().reset_index().rename(columns={\"tracheostomy_flag\": \"tracheostomy_flag_positive\"})\n",
    "hd_flag_positive = cap.groupby(['pt_study_id', 'episode_id'])['hd_flag'].max().reset_index().rename(columns={\"hd_flag\": \"hd_flag_positive\"})\n",
    "\n",
    "summary_tables = [\n",
    "    tracheostomy_flag_positive,\n",
    "    intub_flag_positive,\n",
    "    hd_flag_positive,\n",
    "    crrt_flag_positive,\n",
    "    ecmo_flag_positive\n",
    "]\n",
    "\n",
    "patient_summary = reduce(lambda left, right: pd.merge(left, right, on=['pt_study_id', 'episode_id'], how='outer'), summary_tables)\n",
    "cols = patient_summary.columns\n",
    "cap_only = cap.merge(patient_summary, on=['pt_study_id', 'episode_id'], how='left')\n",
    "\n",
    "cols_with_nan = cap_only[cols].isna().any()\n",
    "cols_with_nan = cols_with_nan[cols_with_nan].index.tolist()\n",
    "print(\"Number of column with missing values:\", len(cols_with_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep episode day 1 for each patient\n",
    "cap_only = cap_only.groupby(['pt_study_id', 'episode_id']).first().reset_index()\n",
    "\n",
    "# set immunocompromised flag to integer\n",
    "cap_only['immunocompromised_flag'] = cap_only['immunocompromised_flag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = 'd7_episode_resolution_binary'\n",
    "nonnormal_cols = ['edw_adm_age', 'bmi', 'hospital_los_days', 'total_icu_los_days', 'episode_duration', 'sofa_score', 'cumulative_nat_score', \n",
    "                  'cumulative_steroid_dose_until_today']\n",
    "\n",
    "categorical_cols = ['external_transfer_flag','race', 'gender', 'ethnicity', \n",
    "                   'discharge_disposition_name', 'unfavorable_outcome', 'immunocompromised_flag', 'smoking_history',\n",
    "                   'ecmo_flag_positive', 'intub_flag_positive', 'hd_flag_positive', 'crrt_flag_positive', 'tracheostomy_flag_positive']\n",
    "\n",
    "all_cols = nonnormal_cols + categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the desired order\n",
    "discharge_order = ['Home', 'Rehab', 'LTACH', 'SNF', 'Hospice','Died']\n",
    "\n",
    "race_order = [\n",
    "    'White',\n",
    "    'Black or African American',\n",
    "    'Asian',\n",
    "    'Unknown or Not Reported',\n",
    "]\n",
    "\n",
    "smoking_order = [\n",
    "    'Never Smoked',\n",
    "    'Former Smoker',\n",
    "    'Current Smoker',\n",
    "    'Unknown'\n",
    "]\n",
    "\n",
    "gender_order = ['Female', 'Male']\n",
    "\n",
    "\n",
    "# Step 2: Set the column as a categorical with the specified order\n",
    "cap_only['discharge_disposition_name'] = pd.Categorical(\n",
    "    cap_only['discharge_disposition_name'],\n",
    "    categories=discharge_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convert cured column\n",
    "cap_only['d7_episode_resolution_binary'] = cap_only['d7_episode_resolution_binary'].replace({\n",
    "    1: 'Not Cured',\n",
    "    0: 'Cured'\n",
    "})\n",
    "\n",
    "# Rename smoking status values\n",
    "cap_only['smoking_history'] = cap_only['smoking_history'].replace({\n",
    "    'No': 'Never Smoked',\n",
    "    'Yes': 'Current Smoker',\n",
    "    'Former': 'Former Smoker',\n",
    "    'Unknown Smoking Status': 'Unknown'\n",
    "})\n",
    "\n",
    "\n",
    "cap_only['smoking_history'] = pd.Categorical(\n",
    "    cap_only['smoking_history'],\n",
    "    categories=smoking_order,\n",
    "    ordered=True)\n",
    "\n",
    "\n",
    "# Convert Race column to a categorical type with the specified order\n",
    "cap_only['race'] = pd.Categorical(\n",
    "    cap_only['race'],\n",
    "    categories=race_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convert gender column\n",
    "cap_only['gender'] = pd.Categorical(\n",
    "    cap_only['gender'],\n",
    "    categories=gender_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convert binary column 1/0 -> Yes/No\n",
    "binary_cols = ['hd_flag_positive', 'immunocompromised_flag', 'external_transfer_flag', \n",
    "               'hd_flag_positive', 'crrt_flag_positive', 'ecmo_flag_positive', 'tracheostomy_flag_positive', \n",
    "               'intub_flag_positive', 'unfavorable_outcome']\n",
    "\n",
    "for b in binary_cols:\n",
    "    cap_only[b] = cap_only[b].replace({\n",
    "        1: 'Yes',\n",
    "        0: 'No'\n",
    "    })\n",
    "\n",
    "# Rename columns\n",
    "col_renames = {\n",
    "    'edw_adm_age': 'Age (years)',\n",
    "    'ethnicity': 'Ethnicity',\n",
    "    'gender': 'Gender',\n",
    "    'race': 'Race',\n",
    "    'smoking_history': 'Smoking Status',\n",
    "    'bmi': 'Body Mass Index (kg/m)',\n",
    "    \n",
    "    'immunocompromised_flag': 'Immunocompromised',\n",
    "    'external_transfer_flag': 'Transferred from External Facility',\n",
    "\n",
    "    'sofa_score': 'SOFA Score on Episode Day 1',\n",
    "\n",
    "    'cumulative_nat_score': 'Cumulative NAT Score on Episode Day 1',\n",
    "    'cumulative_steroid_dose_until_today': 'Cumulative Steroid Dose on Episode Day 1',\n",
    "\n",
    "    \n",
    "    'hd_flag_positive': 'Received hemodialysis during Episode',\n",
    "    'crrt_flag_positive': 'Received CRRT during Episode',\n",
    "    'ecmo_flag_positive': 'Received ECMO during Episode',\n",
    "    'tracheostomy_flag_positive': 'Underwent Tracheostomy',\n",
    "    'intub_flag_positive': 'Intubated During Episode',\n",
    "\n",
    "    'total_icu_los_days': 'Total ICU Days',\n",
    "    'hospital_los_days': 'Total Hospitalization Days',\n",
    "    'episode_duration': 'Episode Duration',\n",
    "\n",
    "    'discharge_disposition_name': 'Discharge Disposition',\n",
    "    'unfavorable_outcome': 'Unfavorable Outcome',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb1 = TableOne(cap_only, \n",
    "               columns=all_cols, categorical=categorical_cols, nonnormal=nonnormal_cols, \n",
    "               groupby=group_by, rename=col_renames, missing=False, pval=True)\n",
    "\n",
    "tb1_df = tb1.tableone\n",
    "\n",
    "# only show value=1 rows for binary column\n",
    "binary_vars = ['Transferred from External Facility', 'Unfavorable Outcome', 'Immunocompromised',\n",
    "               'Received ECMO during Episode', 'Intubated During Episode',\n",
    "               'Received hemodialysis during Episode', 'Received CRRT during Episode', 'Underwent Tracheostomy']\n",
    "\n",
    "\n",
    "rows_to_keep = []\n",
    "for idx in tb1_df.index:\n",
    "    # idx[0] is the variable name, idx[1] is the value\n",
    "    matched = any(var in idx[0] for var in binary_vars)\n",
    "    if matched:\n",
    "        if idx[1] == 'Yes': \n",
    "            rows_to_keep.append(idx)\n",
    "    else:\n",
    "        # For non-binary variables\n",
    "        rows_to_keep.append(idx)\n",
    "\n",
    "tb1_filtered = tb1_df.loc[rows_to_keep]\n",
    "tb1_filtered.to_csv(\"./output/cap_cohort_tb1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Performance table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = results['xgb_Halm\\'s_and_ventilator_features']['y_test']\n",
    "y_pred_prob = results['xgb_Halm\\'s_and_ventilator_features']['test_pred']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "specificity = 1 - fpr\n",
    "sensitivity = tpr\n",
    "\n",
    "fixed_threshold = 0.35\n",
    "file_path = os.path.join(output_path, 'performance_metrics_thresholds_comparison_halsm_only_fixed035')\n",
    "\n",
    "# Interpolate sensitivity and specificity at threshold=0.35\n",
    "interp_sens = np.interp(fixed_threshold, thresholds[::-1], sensitivity[::-1])\n",
    "interp_spec = np.interp(fixed_threshold, thresholds[::-1], specificity[::-1])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, sensitivity, label='Sensitivity (ROC)', lw=2)\n",
    "plt.plot(thresholds, specificity, label='Specificity (ROC)', lw=2)\n",
    "\n",
    "plt.scatter(fixed_threshold, interp_sens, color='red', zorder=5, label=f'Sensitivity at {fixed_threshold:.2f}')\n",
    "plt.scatter(fixed_threshold, interp_spec, color='blue', zorder=5, label=f'Specificity at {fixed_threshold:.2f}')\n",
    "\n",
    "plt.axvline(x=fixed_threshold, color='green', linestyle='--', label=f'Threshold = {fixed_threshold:.2f}')\n",
    "\n",
    "plt.annotate(\n",
    "    f\"Threshold = 0.35\",\n",
    "    xy=(fixed_threshold, (interp_sens + interp_spec) / 2),\n",
    "    xytext=(fixed_threshold - 0.07, (interp_sens + interp_spec) / 2 + 0.05),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "    fontsize=13,\n",
    "    fontweight='bold',\n",
    "    ha='right',\n",
    "    bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3)\n",
    ")\n",
    "\n",
    "plt.xlabel('Threshold', fontsize=15)\n",
    "plt.ylabel('Value', fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.title(f'Performance at Threshold = {fixed_threshold:.2f}', size=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"{file_path}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Youden's J "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_path, 'performance_metrics_best_threshold_youdenJ')\n",
    "\n",
    "y_true = results['xgb_Halm\\'s_and_ventilator_features']['y_test']\n",
    "y_pred_prob = results['xgb_Halm\\'s_and_ventilator_features']['test_pred']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "specificity = 1 - fpr\n",
    "sensitivity = tpr\n",
    "\n",
    "# Calculate Youden's J statistic for all thresholds\n",
    "youden_j = sensitivity + specificity - 1\n",
    "\n",
    "# Find the index of the best Youden's J\n",
    "best_idx = np.argmax(youden_j)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_sens = sensitivity[best_idx]\n",
    "best_spec = specificity[best_idx]\n",
    "best_j = youden_j[best_idx]\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, sensitivity, label='Sensitivity', lw=2)\n",
    "plt.plot(thresholds, specificity, label='Specificity', lw=2)\n",
    "\n",
    "# Highlight and annotate the best threshold\n",
    "plt.scatter(best_threshold, best_sens, color='red', zorder=5, label='Best Sensitivity (Youden\\'s J)')\n",
    "plt.scatter(best_threshold, best_spec, color='blue', zorder=5, label='Best Specificity (Youden\\'s J)')\n",
    "plt.axvline(x=best_threshold, color='green', linewidth=3, linestyle=':', label='Best Threshold')\n",
    "\n",
    "plt.annotate(\n",
    "    f\"Threshold = {best_threshold:.3f}\",\n",
    "    xy=(best_threshold, (best_sens + best_spec) / 2),\n",
    "    xytext=(best_threshold - 0.1, best_j + 0.15),\n",
    "    arrowprops=dict(facecolor='gray', shrink=0.05),\n",
    "    fontsize=13,\n",
    "    ha='right',\n",
    "    fontweight='bold',\n",
    "    bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3)\n",
    ")\n",
    "\n",
    "plt.xlabel('Threshold', fontsize=15)\n",
    "plt.ylabel('Value', fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.title(f'Performance at Threshold = {best_threshold:.3f}', size=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"{file_path}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best threshold < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Best threshold= 0.42470446\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(output_path, 'performance_metrics_best_threshold_below_05')\n",
    "\n",
    "y_true = results['xgb_Halm\\'s_and_ventilator_features']['y_test']\n",
    "y_pred_prob = results['xgb_Halm\\'s_and_ventilator_features']['test_pred']\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "specificity = 1 - fpr\n",
    "sensitivity = tpr\n",
    "\n",
    "# Calculate Youden's J statistic and get the best threshold < 0.5\n",
    "youden_j = sensitivity + specificity - 1\n",
    "mask = thresholds < (0.5 - 1e-10)\n",
    "filtered_thresholds = thresholds[mask]\n",
    "filtered_sens = sensitivity[mask]\n",
    "filtered_spec = specificity[mask]\n",
    "filtered_j = youden_j[mask]\n",
    "\n",
    "if len(filtered_j) > 0:\n",
    "    best_idx = np.argmax(filtered_j)\n",
    "    best_threshold = filtered_thresholds[best_idx]\n",
    "    best_sens = filtered_sens[best_idx]\n",
    "    best_spec = filtered_spec[best_idx]\n",
    "\n",
    "    # set the best value to -inf temporarily and find again\n",
    "    if len(filtered_j) > 1:\n",
    "        temp_j = filtered_j.copy()\n",
    "        temp_j[best_idx] = -np.inf\n",
    "        second_best_idx = np.argmax(temp_j)\n",
    "        second_best_threshold = filtered_thresholds[second_best_idx]\n",
    "        # print(\"Second Best threshold=\", second_best_threshold)\n",
    "    else:\n",
    "        second_best_threshold = None\n",
    "else:\n",
    "    raise ValueError(\"No threshold found < 0.5\")\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, sensitivity, label='Sensitivity', lw=2)\n",
    "plt.plot(thresholds, specificity, label='Specificity', lw=2)\n",
    "\n",
    "# Only highlight and annotate the best threshold < 0.5\n",
    "plt.scatter(best_threshold, best_sens, color='red', zorder=5, label=f'Best Sensitivity < 0.5 (Youden\\'s J)')\n",
    "plt.scatter(best_threshold, best_spec, color='blue', zorder=5, label=f'Best Specificity < 0.5 (Youden\\'s J)')\n",
    "plt.axvline(x=best_threshold, color='green', linewidth=3, linestyle=':', label=f'Best Threshold')\n",
    "\n",
    "plt.annotate(\n",
    "    f\"Threshold = {best_threshold:.3f} \",\n",
    "    xy=(best_threshold, (best_sens + best_spec) / 2),\n",
    "    xytext=(best_threshold - 0.07, (best_sens + best_spec) / 2 + 0.12),\n",
    "    arrowprops=dict(facecolor='gray', shrink=0.05),\n",
    "    fontsize=13,\n",
    "    ha='right',\n",
    "    fontweight='bold',\n",
    "    bbox=dict(boxstyle='round,pad=0.2', fc='yellow', alpha=0.3)\n",
    ")\n",
    "\n",
    "plt.xlabel('Threshold', fontsize=15)\n",
    "plt.ylabel('Value', fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.title(f'Performance at Threshold = {best_threshold:.3f}', size=20)\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"{file_path}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation\n",
      "Accuracy: 0.725\n",
      "Sensitivity: 0.667\n",
      "Specificity: 0.778\n",
      "AUROC: 0.799\n",
      "F1 Score: 0.696\n",
      "AUPR: 0.815\n",
      "PPV: 0.727\n",
      "NPV: 0.724\n",
      "Test Set Evaluation\n",
      "Accuracy: 0.667\n",
      "Sensitivity: 0.833\n",
      "Specificity: 0.519\n",
      "AUROC: 0.799\n",
      "F1 Score: 0.702\n",
      "AUPR: 0.815\n",
      "PPV: 0.606\n",
      "NPV: 0.778\n"
     ]
    }
   ],
   "source": [
    "metrics_model_1 = get_metrics_dict(results['xgb_worst_Halm\\'s_features'])\n",
    "metrics_model_2 = get_metrics_dict(results['xgb_Halm\\'s_and_ventilator_features'])\n",
    "metrics_baseline = get_metrics_dict(results['halms_baseline'])\n",
    "\n",
    "# get scores\n",
    "best_model = results['xgb_Halm\\'s_and_ventilator_features']['model']\n",
    "X_train_ = results['xgb_Halm\\'s_and_ventilator_features']['X_train']\n",
    "X_test_ = results['xgb_Halm\\'s_and_ventilator_features']['X_test']\n",
    "y_train_ = results['xgb_Halm\\'s_and_ventilator_features']['y_train']\n",
    "y_test_ = results['xgb_Halm\\'s_and_ventilator_features']['y_test']\n",
    "\n",
    "# set the threshold (best)\n",
    "new_results = evaluate_model(best_model, X_train_, X_test_, y_train_, y_test_, threshold=best_threshold)\n",
    "metrics_model_best = get_metrics_dict(new_results)\n",
    "\n",
    "# set the threshold (fixed)\n",
    "new_results_fixed = evaluate_model(best_model, X_train_, X_test_, y_train_, y_test_, threshold=fixed_threshold)\n",
    "metrics_model_fixed = get_metrics_dict(new_results_fixed)\n",
    "\n",
    "# save performance metrics\n",
    "summary_df = pd.DataFrame([metrics_baseline, metrics_model_1, metrics_model_2, metrics_model_best, metrics_model_fixed],\n",
    "                          index=['Baseline', 'XGBoost Model Halms Only', 'XGBoost Model with Worst Vents', \n",
    "                                 'XGBoost Model Halms with Vents with Best Threshold',\n",
    "                                 'XGBoost Model Halms with Vents with Fixed Threshold(0.35)'])\n",
    "\n",
    "summary_df.to_csv(\"./output/plots/preformance_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_path, 'cap_pred_confusion_matrices_comparison')\n",
    "\n",
    "cm_model1 = results[\"xgb_worst_Halm\\'s_features\"][\"metrics\"][\"confusion_matrix\"]\n",
    "cm_model2 = results['xgb_Halm\\'s_and_ventilator_features'][\"metrics\"][\"confusion_matrix\"]\n",
    "cm_model3 = new_results['metrics']['confusion_matrix']\n",
    "cm_model4 = new_results_fixed['metrics']['confusion_matrix']\n",
    "labels = ['Cured', 'Not Cured']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "# Halm's only\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm_model1, display_labels=labels)\n",
    "disp1.plot(ax=axes[0], colorbar=False, cmap='Blues')\n",
    "axes[0].set_title(\"Halm's Features\", fontsize=10)\n",
    "\n",
    "# Halm's only with lab\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_model2, display_labels=labels)\n",
    "disp2.plot(ax=axes[1], colorbar=False, cmap='Blues')\n",
    "axes[1].set_title(\"Halm's and Ventilator Features\", fontsize=10)\n",
    "\n",
    "# Halm's only with best threshold\n",
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=cm_model3, display_labels=labels)\n",
    "disp3.plot(ax=axes[2], colorbar=False, cmap='Blues')\n",
    "axes[2].set_title(f\"Halm's and Ventilator Features\\n(Threshold={best_threshold:.3f})\", fontsize=10)\n",
    "\n",
    "# change text size\n",
    "desired_fontsize = 15\n",
    "\n",
    "for ax in axes:\n",
    "    for text in ax.texts:\n",
    "        text.set_fontsize(desired_fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"{file_path}.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best threshold only (Best threshold < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_path, 'cap_pred_confusion_matrices_best_threshold')\n",
    "\n",
    "# Halm's only with best threshold\n",
    "# Swap labels for x and y axes\n",
    "cm_model3_swapped = cm_model3.T\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_model3_swapped, display_labels=labels)\n",
    "disp.plot(colorbar=False, cmap='Blues')\n",
    "plt.title(f\"Halm's and Ventilator Features\\n(Threshold={best_threshold:.3f})\", fontsize=18)\n",
    "plt.xlabel('True Label', fontsize=15)        \n",
    "plt.ylabel('Predicted Label', fontsize=15)   \n",
    "plt.xticks(fontsize=13, fontweight='bold')\n",
    "plt.yticks(fontsize=13, fontweight='bold')\n",
    "ax = plt.gca()\n",
    "for text in ax.texts:\n",
    "    text.set_fontsize(16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}_swapped.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"{file_path}_swapped.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed threshold only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_path, 'cap_pred_confusion_matrices_best_threshold')\n",
    "\n",
    "# Halm's only with best threshold\n",
    "# Swap labels for x and y axes\n",
    "cm_model4_swapped = cm_model4.T\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_model4_swapped, display_labels=labels)\n",
    "disp.plot(colorbar=False, cmap='Blues')\n",
    "plt.title(f\"Halm's and Ventilator Features\\n(Threshold={fixed_threshold:.2f})\", fontsize=18)\n",
    "plt.xlabel('True Label', fontsize=15)        \n",
    "plt.ylabel('Predicted Label', fontsize=15)   \n",
    "plt.xticks(fontsize=13, fontweight='bold')\n",
    "plt.yticks(fontsize=13, fontweight='bold')\n",
    "ax = plt.gca()\n",
    "for text in ax.texts:\n",
    "    text.set_fontsize(16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{file_path}_swapped_fixed_threshold.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"{file_path}_swapped_fixed_threshold.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
